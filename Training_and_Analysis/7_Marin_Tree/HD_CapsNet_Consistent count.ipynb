{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b24df6d",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"6\"><center><b> HD-CapsNet: A Hierarchical Deep Capsule Network for Image Classification </b></center></font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691c83f",
   "metadata": {},
   "source": [
    "**Changing Model Architecture**\n",
    "- **(Mod-3.1)** 32D>16D>8D (Coarse>Medium>FINE) use skip connections between Secondary Capsules $Concatenate([P_{caps}, S_{coarse}])$ > input for $S_{medium}$ and $Concatenate([P_{caps}, S_{medium}])$ > input for $S_{fine}$\n",
    "- With $L_{Cons}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9d6d5",
   "metadata": {},
   "source": [
    "# Files and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4aa737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "# Supporting Libraries:\n",
    "    #Mathplot lib for ploting graphs\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "    # numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    #system\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "    #import other libraries\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from treelib import Tree\n",
    "    # ML model, Dataset and evalution metrics\n",
    "sys.path.append('../../') ### adding system parth for src folder\n",
    "from src import datasets # load datasets\n",
    "from src import MixUp # load datasets\n",
    "from src import MixUp_add_loss # load datasets\n",
    "from src import metrics # load hierarchcial metrics\n",
    "from src import sysenv # load hierarchcial metrics\n",
    "from src import models # load machine learning models\n",
    "\n",
    "    ## Tensorflow_docs\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "    # Auto reload local libraries if updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c610b",
   "metadata": {},
   "source": [
    "# System information & GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506c959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m\n",
      "• Computer Name = \u001b[0m30BFPC1AXW95\u001b[91m\u001b[1m\n",
      "• Working Directory = \u001b[0mC:\\Users\\knoor\\OneDrive - Deakin University\\Deep Learning with Python\\Google_Drive\\Projects\\Deep Learning\\HD-CapsNet\\Training_and_Analysis\\7_Marin_Tree\u001b[91m\u001b[1m\n",
      "• Python Version = \u001b[0m3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]\u001b[91m\u001b[1m\n",
      "• TensorFlow Version = \u001b[0m2.8.0\u001b[91m\u001b[1m\n",
      "• Keras Version = \u001b[0m2.8.0\u001b[91m\u001b[1m\n",
      "• Current Environment = \u001b[0mAnaconda Environment Name : py38tf\n"
     ]
    }
   ],
   "source": [
    "systeminfo = sysenv.systeminfo()\n",
    "print(systeminfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832d5a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following GPUS are selected =  0\n",
      "Done: GPU PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = \"0,1,2,3,4,5,6,7\" ## Selecting Available gpus (Multi-GPUS)\n",
    "gpus = \"0\" ## Selecting Available gpus (Single GPU)\n",
    "gpugrowth = sysenv.gpugrowth(gpus = gpus) ## Limiting GPUS from OS environment\n",
    "gpugrowth.memory_growth() #GPU memory growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd551837",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445ee1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"n_epochs\" : 100,\n",
    "                \"batch_size\": 64,\n",
    "                \"lr\": 0.001, # Initial learning rate\n",
    "                \"lr_decay\": 0.95, # Learning rate decay\n",
    "                \"decay_exe\": 9, #learning rate decay execution epoch after\n",
    "               }\n",
    "model_params = {\"optimizer\": tf.keras.optimizers.Adam(train_params['lr']),\n",
    "                \"loss_function\": models.MarginLoss(),\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98815c",
   "metadata": {},
   "source": [
    "# log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ace371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Folder already exist.\n"
     ]
    }
   ],
   "source": [
    "directory = sysenv.log_dir('7_Marine_Tree/HD_CapsNet/Mod_3_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfde972",
   "metadata": {},
   "source": [
    "# Import Dataset : Marine Tree Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4714d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.get_Marine_dataset(output_level='level_depth_3', # 'level_depth_3', 'level_depth_4', 'level_depth_5\n",
    "                                      dataset_path ='D:\\Datasets\\Marine_tree', ## Path to the dataset directory\n",
    "#                                       dataset_path ='/home/knoor/Downloads/RunningOnServer/H-CapsNet_Revision/Dataset/Marine_tree', ## Path to the dataset directory\n",
    "                                      image_size=(64,64),\n",
    "                                      batch_size=train_params['batch_size'],\n",
    "                                      subtype='Combined',\n",
    "                                      data_normalizing ='normalize',\n",
    "                                      class_encoding = 'One_Hot_Encoder',\n",
    "                                      data_augmantation = 'mixup'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "366d667f",
   "metadata": {},
   "source": [
    "for x,y in dataset.train_dataset.take(1):\n",
    "    for i in range(len(x)):\n",
    "        print('Example = ', i)\n",
    "        plt.imshow(x[i])\n",
    "        plt.show()\n",
    "        print('Coarse =', {k:v for k,v in enumerate(y[0][i].numpy()) if v != 0}) # coarse lables\n",
    "        print('Medium =', {k:v for k,v in enumerate(y[1][i].numpy()) if v != 0}) # medium lables\n",
    "        print('Fine   =', {k:v for k,v in enumerate(y[2][i].numpy()) if v != 0}) # fine lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d4db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in dataset.train_dataset.take(1):\n",
    "    image_shape = x.shape[1:]\n",
    "    coarse_label_shape = y[0].shape[1:]\n",
    "    medium_label_shape = y[1].shape[1:]\n",
    "    fine_label_shape = y[2].shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38ee07",
   "metadata": {},
   "source": [
    "## Learning Rate Decay Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ed77d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    learning_rate_init = train_params[\"lr\"]\n",
    "    \n",
    "    if epoch > train_params[\"decay_exe\"]:\n",
    "        learning_rate_init = train_params[\"lr\"] * (train_params[\"lr_decay\"] ** (epoch-9))\n",
    "        \n",
    "    tf.summary.scalar('learning rate', data=learning_rate_init, step=epoch)\n",
    "        \n",
    "    return learning_rate_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5ea00",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee6349a",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48854261",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_class, medium_class, fine_class = dataset.num_classes\n",
    "\n",
    "## For Dynamic LossWeights\n",
    "initial_lw = models.initial_lw({\"coarse\": coarse_class,\n",
    "                                 \"medium\": medium_class,\n",
    "                                 \"fine\": fine_class})\n",
    "\n",
    "lossweight = {'coarse_lw' : K.variable(value = initial_lw['coarse'], dtype=\"float32\", name=\"coarse_lw\"),\n",
    "             'medium_lw' : K.variable(value = initial_lw['medium'], dtype=\"float32\", name=\"medium_lw\"),\n",
    "             'fine_lw' : K.variable(value = initial_lw['fine'], dtype=\"float32\", name=\"fine_lw\"),\n",
    "              'decoder_lw' : 0.0\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b69892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_coarse_to_medium_OneHot = dataset.Matrix_coarse_to_medium_OneHot\n",
    "Matrix_medium_to_fine_OneHot = dataset.Matrix_medium_to_fine_OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796bab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_proba):\n",
    "    \n",
    "    present_error_raw = tf.square(tf.maximum(0., 0.9 - y_proba), name=\"present_error_raw\")\n",
    "    absent_error_raw = tf.square(tf.maximum(0., y_proba - 0.1), name=\"absent_error_raw\")\n",
    "    L = tf.add(y_true * present_error_raw, 0.5 * (1.0 - y_true) * absent_error_raw,name=\"L\")\n",
    "    total_marginloss = tf.reduce_sum(L, axis=1, name=\"margin_loss\")\n",
    "\n",
    "    return total_marginloss\n",
    "\n",
    "\n",
    "def consistency_check(y_pred_ancestor,y_pred_current,lookup_matrix,num_class_current):\n",
    "    pred_max_ancestor = tf.argmax(y_pred_ancestor,axis=1)\n",
    "    pred_max_current = tf.argmax(y_pred_current,axis=1)\n",
    "    \n",
    "    consistant_check = tf.gather(lookup_matrix, indices=pred_max_ancestor)*tf.one_hot(pred_max_current,num_class_current)\n",
    "    \n",
    "    return tf.reduce_sum(consistant_check,1)\n",
    "\n",
    "def get_consistency(y_true_ancestor, y_pred, lookup_matrix):\n",
    "    '''\n",
    "    Get consistency based on 2 levels\n",
    "    Provide ture levels for the level above, predictions for the current level and a look up metrix\n",
    "    '''\n",
    "    y_prob = tf.math.divide(y_pred,tf.reshape(tf.reduce_sum(y_pred,-1),(-1,1),name='reshape'),name='Probability')\n",
    "    \n",
    "    index_for_predictions = tf.cast(tf.math.argmax(y_true_ancestor,axis=1),dtype= 'int32')\n",
    "    consistent_fine = tf.gather(lookup_matrix, indices=index_for_predictions) * y_prob\n",
    "    Consistency_sum_array = tf.reduce_sum(consistent_fine, axis =1)\n",
    "    \n",
    "    return tf.abs(1-Consistency_sum_array)\n",
    "\n",
    "def CustomLoss(y_true_c, y_true_m, y_true_f, y_pred_c, y_pred_m, y_pred_f, LW_C, LW_M, LW_F,\n",
    "               number_of_classes_m, number_of_classes_f, C_Weight=0.2):\n",
    "    \n",
    "    con_m = consistency_check(y_pred_c,y_pred_m,Matrix_coarse_to_medium_OneHot,num_class_current=number_of_classes_m)\n",
    "    con_m_not = tf.abs(con_m-1)\n",
    "    \n",
    "    con_f = consistency_check(y_pred_m,y_pred_f,Matrix_medium_to_fine_OneHot,num_class_current=number_of_classes_f)\n",
    "    con_f_not = tf.abs(con_f-1)\n",
    "    \n",
    "    con_sum_m = get_consistency(y_true_c,y_pred_m,Matrix_coarse_to_medium_OneHot)\n",
    "    con_sum_f = get_consistency(y_true_m,y_pred_f,Matrix_medium_to_fine_OneHot)\n",
    "    \n",
    "    medium_lvl_cosistency = con_sum_m * con_m_not\n",
    "    fine_lvl_cosistency = con_sum_f * con_f_not    \n",
    "   \n",
    "    ML_c = margin_loss(y_true_c, y_pred_c)*LW_C\n",
    "    ML_m = LW_M*((1-C_Weight)*(margin_loss(y_true_m, y_pred_m))+C_Weight*(medium_lvl_cosistency))\n",
    "    ML_f = LW_F*((1-C_Weight)*(margin_loss(y_true_f, y_pred_f))+C_Weight*(fine_lvl_cosistency))\n",
    "    \n",
    "    batch_loss = ML_c + ML_m+ ML_f\n",
    "\n",
    "    return tf.reduce_mean(batch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a497572",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f935c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    \n",
    "    ## Calling the HD-CapsNet Model\n",
    "    model = models.HD_CapsNet_Mod_3_3(input_shape     = image_shape, \n",
    "                                      input_shape_yc  = coarse_label_shape,\n",
    "                                      input_shape_ym  = medium_label_shape,\n",
    "                                      input_shape_yf  = fine_label_shape, \n",
    "                                      no_coarse_class = coarse_class, \n",
    "                                      no_medium_class = medium_class, \n",
    "                                      no_fine_class   = fine_class,\n",
    "                                      PCap_n_dims     = 8, \n",
    "                                      SCap_f_dims     = 16, \n",
    "                                      SCap_m_dims     = 32, \n",
    "                                      SCap_c_dims     = 64)\n",
    "    \n",
    "    ## Saving Model Architecture\n",
    "#     keras.utils.plot_model(model, to_file = directory+\"/Architecture.png\", show_shapes=True)\n",
    "    \n",
    "    ## Add Loss for Model\n",
    "    model.add_loss(CustomLoss(y_true_c            = model.inputs[1], \n",
    "                              y_true_m            = model.inputs[2], \n",
    "                              y_true_f            = model.inputs[3], \n",
    "                              y_pred_c            = model.output[0], \n",
    "                              y_pred_m            = model.output[1], \n",
    "                              y_pred_f            = model.output[2], \n",
    "                              LW_C                = lossweight['coarse_lw'], \n",
    "                              LW_M                = lossweight['medium_lw'], \n",
    "                              LW_F                = lossweight['fine_lw'],\n",
    "                              number_of_classes_m = medium_class, \n",
    "                              number_of_classes_f = fine_class, \n",
    "                              C_Weight            =0.2)\n",
    "                  )\n",
    "    \n",
    "    ## Compile Model\n",
    "    model.compile(optimizer='adam',                  \n",
    "                  metrics={'prediction_fine': 'accuracy',\n",
    "                           'prediction_medium': 'accuracy',\n",
    "                           'prediction_coarse': 'accuracy'}\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86393b7d",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05797918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_9), but are not present in its tracked objects:   <tf.Variable 'coarse_lw:0' shape=() dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    }
   ],
   "source": [
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3acd8d7",
   "metadata": {},
   "source": [
    "strategy = models.multi_gpu_select('windows')\n",
    "\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e4b982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HD-CapsNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_Image (InputLayer)       [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 64, 64, 64)   1792        ['Input_Image[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 64, 64)  256         ['block1_conv1[0][0]']           \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 64, 64, 64)   36928       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 64, 64)  256         ['block1_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 32, 32, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 32, 32, 128)  73856       ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 128)  512        ['block2_conv1[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 32, 32, 128)  147584      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 128)  512        ['block2_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 16, 16, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 16, 16, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['block3_conv1[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 16, 16, 256)  590080      ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['block3_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 8, 8, 256)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 8, 8, 512)    1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 512)   2048        ['block4_conv1[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 8, 8, 512)    2359808     ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 512)   2048        ['block4_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 4, 4, 512)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape_layer (Reshape)        (None, 1024, 8)      0           ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " p_caps (Lambda)                (None, 1024, 8)      0           ['reshape_layer[0][0]']          \n",
      "                                                                                                  \n",
      " s_caps_coarse (SecondaryCapsul  (None, 2, 64)       1048576     ['p_caps[0][0]']                 \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " primary_skip_m (Reshape)       (None, 128, 64)      0           ['p_caps[0][0]']                 \n",
      "                                                                                                  \n",
      " skip_connection_m (Concatenate  (None, 130, 64)     0           ['primary_skip_m[0][0]',         \n",
      " )                                                                's_caps_coarse[0][0]']          \n",
      "                                                                                                  \n",
      " s_caps_medium (SecondaryCapsul  (None, 10, 32)      2662400     ['skip_connection_m[0][0]']      \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " primary_skip_f (Reshape)       (None, 256, 32)      0           ['p_caps[0][0]']                 \n",
      "                                                                                                  \n",
      " skip_connection_f (Concatenate  (None, 266, 32)     0           ['primary_skip_f[0][0]',         \n",
      " )                                                                's_caps_medium[0][0]']          \n",
      "                                                                                                  \n",
      " s_caps_fine (SecondaryCapsule)  (None, 38, 16)      5175296     ['skip_connection_f[0][0]']      \n",
      "                                                                                                  \n",
      " input_yc (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_ym (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_yf (InputLayer)          [(None, 38)]         0           []                               \n",
      "                                                                                                  \n",
      " prediction_coarse (LengthLayer  (None, 2)           0           ['s_caps_coarse[0][0]']          \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " prediction_medium (LengthLayer  (None, 10)          0           ['s_caps_medium[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prediction_fine (LengthLayer)  (None, 38)           0           ['s_caps_fine[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.argmax_4 (TFOpLambda)  (None,)              0           ['input_yc[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_2 (TFOpLamb  (None,)             0           ['prediction_medium[0][0]']      \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None,)              0           ['tf.math.argmax_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1)            0           ['tf.math.reduce_sum_2[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.argmax (TFOpLambda)    (None,)              0           ['prediction_coarse[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.argmax_1 (TFOpLambda)  (None,)              0           ['prediction_medium[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.argmax_5 (TFOpLambda)  (None,)              0           ['input_ym[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_4 (TFOpLamb  (None,)             0           ['prediction_fine[0][0]']        \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.subtract_7 (TFOpLambda  (None, 10)          0           ['prediction_medium[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_8 (TFOpLambda  (None, 10)          0           ['prediction_medium[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_2 (TFOpLam  (None, 10)          0           ['tf.cast[0][0]']                \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.divide (TFOpLambda)    (None, 10)           0           ['prediction_medium[0][0]',      \n",
      "                                                                  'tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather (TFOpLambd  (None, 10)          0           ['tf.math.argmax[0][0]']         \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.one_hot (TFOpLambda)        (None, 10)           0           ['tf.math.argmax_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None,)              0           ['tf.math.argmax_5[0][0]']       \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 1)            0           ['tf.math.reduce_sum_4[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.argmax_2 (TFOpLambda)  (None,)              0           ['prediction_medium[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.argmax_3 (TFOpLambda)  (None,)              0           ['prediction_fine[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.maximum_2 (TFOpLambda)  (None, 10)          0           ['tf.math.subtract_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_9 (TFOpLambda  (None, 10)          0           ['input_ym[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum_3 (TFOpLambda)  (None, 10)          0           ['tf.math.subtract_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 10)          0           ['tf.compat.v1.gather_2[0][0]',  \n",
      " )                                                                'tf.math.divide[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 10)           0           ['tf.compat.v1.gather[0][0]',    \n",
      "                                                                  'tf.one_hot[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.subtract_10 (TFOpLambd  (None, 38)          0           ['prediction_fine[0][0]']        \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.subtract_11 (TFOpLambd  (None, 38)          0           ['prediction_fine[0][0]']        \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_3 (TFOpLam  (None, 38)          0           ['tf.cast_1[0][0]']              \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.divide_1 (TFOpLambda)  (None, 38)           0           ['prediction_fine[0][0]',        \n",
      "                                                                  'tf.reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_1 (TFOpLam  (None, 38)          0           ['tf.math.argmax_2[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.one_hot_1 (TFOpLambda)      (None, 38)           0           ['tf.math.argmax_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLambda  (None, 2)           0           ['prediction_coarse[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLambda  (None, 2)           0           ['prediction_coarse[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.square_2 (TFOpLambda)  (None, 10)           0           ['tf.math.maximum_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None, 10)          0           ['tf.math.subtract_9[0][0]']     \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.square_3 (TFOpLambda)  (None, 10)           0           ['tf.math.maximum_3[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_3 (TFOpLamb  (None,)             0           ['tf.math.multiply_2[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum_4 (TFOpLambda)  (None, 38)          0           ['tf.math.subtract_10[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_12 (TFOpLambd  (None, 38)          0           ['input_yf[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.maximum_5 (TFOpLambda)  (None, 38)          0           ['tf.math.subtract_11[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 38)          0           ['tf.compat.v1.gather_3[0][0]',  \n",
      " )                                                                'tf.math.divide_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 38)          0           ['tf.compat.v1.gather_1[0][0]',  \n",
      " )                                                                'tf.one_hot_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   (None, 2)            0           ['tf.math.subtract_4[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLambda  (None, 2)           0           ['input_yc[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum_1 (TFOpLambda)  (None, 2)           0           ['tf.math.subtract_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None, 10)          0           ['input_ym[0][0]',               \n",
      " a)                                                               'tf.math.square_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  (None, 10)          0           ['tf.math.multiply_11[0][0]',    \n",
      " a)                                                               'tf.math.square_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_3[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None,)              0           ['tf.math.reduce_sum[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.square_4 (TFOpLambda)  (None, 38)           0           ['tf.math.maximum_4[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpLambd  (None, 38)          0           ['tf.math.subtract_12[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.square_5 (TFOpLambda)  (None, 38)           0           ['tf.math.maximum_5[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_5 (TFOpLamb  (None,)             0           ['tf.math.multiply_3[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.multiply_1[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 2)            0           ['tf.math.maximum[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 2)           0           ['tf.math.subtract_6[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.square_1 (TFOpLambda)  (None, 2)            0           ['tf.math.maximum_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.add_1 (TFOpLambda)     (None, 10)           0           ['tf.math.multiply_10[0][0]',    \n",
      "                                                                  'tf.math.multiply_12[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.abs_2 (TFOpLambda)     (None,)              0           ['tf.math.subtract_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.abs (TFOpLambda)       (None,)              0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpLambd  (None, 38)          0           ['input_yf[0][0]',               \n",
      " a)                                                               'tf.math.square_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpLambd  (None, 38)          0           ['tf.math.multiply_17[0][0]',    \n",
      " a)                                                               'tf.math.square_5[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_5[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_1[0][0]']   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 2)           0           ['input_yc[0][0]',               \n",
      " )                                                                'tf.math.square[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 2)           0           ['tf.math.multiply_7[0][0]',     \n",
      " )                                                                'tf.math.square_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_7 (TFOpLamb  (None,)             0           ['tf.math.add_1[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None,)             0           ['tf.math.abs_2[0][0]',          \n",
      " )                                                                'tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.add_2 (TFOpLambda)     (None, 38)           0           ['tf.math.multiply_16[0][0]',    \n",
      "                                                                  'tf.math.multiply_18[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.abs_3 (TFOpLambda)     (None,)              0           ['tf.math.subtract_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.abs_1 (TFOpLambda)     (None,)              0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)       (None, 2)            0           ['tf.math.multiply_6[0][0]',     \n",
      "                                                                  'tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpLambd  (None,)             0           ['tf.math.reduce_sum_7[0][0]']   \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpLambd  (None,)             0           ['tf.math.multiply_4[0][0]']     \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_8 (TFOpLamb  (None,)             0           ['tf.math.add_2[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None,)             0           ['tf.math.abs_3[0][0]',          \n",
      " )                                                                'tf.math.abs_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_6 (TFOpLamb  (None,)             0           ['tf.math.add[0][0]']            \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None,)             0           ['tf.math.multiply_13[0][0]',    \n",
      " da)                                                              'tf.math.multiply_14[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpLambd  (None,)             0           ['tf.math.reduce_sum_8[0][0]']   \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpLambd  (None,)             0           ['tf.math.multiply_5[0][0]']     \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_6[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpLambd  (None,)             0           ['tf.__operators__.add[0][0]']   \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.math.multiply_19[0][0]',    \n",
      " mbda)                                                            'tf.math.multiply_20[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None,)             0           ['tf.math.multiply_9[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_15[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpLambd  (None,)             0           ['tf.__operators__.add_1[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None,)             0           ['tf.__operators__.add_2[0][0]', \n",
      " mbda)                                                            'tf.math.multiply_21[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.__operators__.add_3[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,579,328\n",
      "Trainable params: 13,575,488\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# keras.utils.plot_model(model, to_file = directory+\"/Architecture.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d887",
   "metadata": {},
   "source": [
    "## Training Pipeline Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d82a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Matching the pipeling with model inputs\n",
    "def pipeline_multi_input_output(image, label):\n",
    "    label_0 = label[0]\n",
    "    label_1 = label[1]\n",
    "    label_2 = label[2]\n",
    "    return (image, label_0, label_1, label_2), (label_0, label_1, label_2)\n",
    "\n",
    "training_dataset_match = dataset.train_dataset.map(pipeline_multi_input_output) ## Mixup dataset\n",
    "val_dataset_match = dataset.val_dataset.map(pipeline_multi_input_output) ## Val Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67d719",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e764da6",
   "metadata": {},
   "source": [
    "tb = keras.callbacks.TensorBoard(directory+'./tb_logs'+ datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "log = keras.callbacks.CSVLogger(directory+'/log.csv', append=True)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(directory+'/epoch-best.h5',\n",
    "                                             monitor='val_prediction_fine_accuracy',\n",
    "                                             save_best_only=True, \n",
    "                                             save_weights_only=True, \n",
    "                                             verbose=1)\n",
    "\n",
    "change_lw = models.LossWeightsModifier(lossweight = lossweight,\n",
    "                                       initial_lw = initial_lw,\n",
    "                                       directory = directory)\n",
    "\n",
    "lr_decay = keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc176a2",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eac4a0be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_save_dir = str(directory+'/trained_model.h5')\n",
    "model.load_weights(model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08f53b",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa6652e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = keras.Model(model.inputs[:1], model.output)\n",
    "final_model.load_weights(directory+'/epoch-best.h5')\n",
    "\n",
    "lossfn = models.MarginLoss()\n",
    "final_model.compile(optimizer='adam', \n",
    "                    loss={'prediction_fine' : lossfn,\n",
    "                          'prediction_medium' : lossfn,\n",
    "                          'prediction_coarse' : lossfn},\n",
    "\n",
    "                    loss_weights={'prediction_fine' : lossweight['fine_lw'],\n",
    "                                  'prediction_medium' : lossweight['medium_lw'],\n",
    "                                  'prediction_coarse' : lossweight['coarse_lw']},\n",
    "\n",
    "                    metrics={'prediction_fine': 'accuracy',\n",
    "                             'prediction_medium': 'accuracy',\n",
    "                             'prediction_coarse': 'accuracy'\n",
    "                            }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d42d95d4",
   "metadata": {},
   "source": [
    "image = []\n",
    "ds_labels0=[]\n",
    "ds_labels1=[]\n",
    "ds_labels2=[]\n",
    "\n",
    "for images, labels in val_dataset.unbatch():\n",
    "    image.append(images[0].numpy()) # or labels.numpy().argmax() for int labels\n",
    "    ds_labels0.append(images[1].numpy()) # or labels.numpy().argmax() for int labels\n",
    "    ds_labels1.append(images[2].numpy()) # or labels.numpy().argmax() for int labels\n",
    "    ds_labels2.append(images[3].numpy()) # or labels.numpy().argmax() for int labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e225c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419/419 [==============================] - 192s 445ms/step - loss: 0.1418 - prediction_coarse_loss: 0.0744 - prediction_medium_loss: 0.1692 - prediction_fine_loss: 0.3199 - prediction_coarse_accuracy: 0.8988 - prediction_medium_accuracy: 0.7860 - prediction_fine_accuracy: 0.5715\n",
      "1. loss ==> 0.14178286492824554\n",
      "2. prediction_coarse_loss ==> 0.07444676756858826\n",
      "3. prediction_medium_loss ==> 0.1691640168428421\n",
      "4. prediction_fine_loss ==> 0.3198564052581787\n",
      "5. prediction_coarse_accuracy ==> 0.8987610936164856\n",
      "6. prediction_medium_accuracy ==> 0.7859914898872375\n",
      "7. prediction_fine_accuracy ==> 0.5715351700782776\n"
     ]
    }
   ],
   "source": [
    "results = final_model.evaluate(dataset.test_dataset)\n",
    "for n in range(len(results)):\n",
    "    print(str(n+1)+'.',final_model.metrics_names[n], '==>', results[n])\n",
    "# model_predictions = final_model.predict(dataset.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f67911a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_pipeline(model, dataset):\n",
    "    y_pred_c = []\n",
    "    y_pred_m = []\n",
    "    y_pred_f = []\n",
    "    \n",
    "    y_true_c = []\n",
    "    y_true_m = []\n",
    "    y_true_f = []\n",
    "    for x, y in dataset:\n",
    "        batch_pred = model.predict(x)\n",
    "        \n",
    "        y_true_c.extend(y[0].numpy().tolist())\n",
    "        y_true_m.extend(y[1].numpy().tolist())\n",
    "        y_true_f.extend(y[2].numpy().tolist())\n",
    "        \n",
    "        y_pred_c.extend(batch_pred[0].tolist())\n",
    "        y_pred_m.extend(batch_pred[1].tolist())\n",
    "        y_pred_f.extend(batch_pred[2].tolist())\n",
    "        \n",
    "    return np.array(y_true_c), np.array(y_true_m), np.array(y_true_f), np.array(y_pred_c), np.array(y_pred_m), np.array(y_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91eb4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_c, y_true_m, y_true_f, y_pred_c, y_pred_m, y_pred_f = predict_from_pipeline(final_model, dataset.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f34a20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hierarchical Precision = 0.7501946662686269 \n",
      "Hierarchical Recall = 0.760442321566286 \n",
      "Hierarchical F1-Score = 0.7543682186659274 \n",
      "Consistency =  0.9447346816926636 \n",
      "Exact Match =  0.5559370102246436\n"
     ]
    }
   ],
   "source": [
    "h_measurements,consistency,exact_match = metrics.hmeasurements([y_true_c, y_true_m, y_true_f],\n",
    "                                                               [y_pred_c, y_pred_m, y_pred_f],\n",
    "                                                               dataset.get_tree())\n",
    "print('\\nHierarchical Precision =',h_measurements[0],\n",
    "      '\\nHierarchical Recall =', h_measurements[1],\n",
    "      '\\nHierarchical F1-Score =',h_measurements[2],\n",
    "      '\\nConsistency = ', consistency,\n",
    "      '\\nExact Match = ', exact_match,\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338b504",
   "metadata": {},
   "source": [
    "# Consistency count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd7b31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Examples =  26798\n",
      "model Consistency =  0.9447346816926636\n",
      "Number of Consistent Examples =  25317\n",
      "Number of Not Consistent Examples =  1481\n"
     ]
    }
   ],
   "source": [
    "def get_model_consistency(y_pred: list, tree: Tree):\n",
    "    \"\"\"\n",
    "    This methods estimates the consistency.\n",
    "\n",
    "    :param y_pred: a 2d array where d1 is the taxonomy level, and d2 is the prediction for each example.\n",
    "    :type y_pred: np.array\n",
    "    :param tree: A tree of the taxonomy.\n",
    "    :type tree: Tree\n",
    "    :return: value of consistency.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    y_pred = [np.argmax(x, axis=1) for x in y_pred]\n",
    "    consistency = []\n",
    "    not_consistent = {}\n",
    "    for j in range(len(y_pred[0])):\n",
    "        v = 1\n",
    "        for i in range(len(y_pred) - 1):\n",
    "            parent = 'L' + str(i) + '_' + str(y_pred[i][j])\n",
    "            child = 'L' + str(i + 1) + '_' + str(y_pred[i + 1][j])\n",
    "            if tree.parent(child).identifier != parent:\n",
    "                v = 0\n",
    "                break\n",
    "        consistency.append(v)\n",
    "    return consistency\n",
    "\n",
    "model_consistency = get_model_consistency([y_pred_c, y_pred_m, y_pred_f],\n",
    "                                          dataset.get_tree())\n",
    "\n",
    "print('Total Examples = ',len(model_consistency)) # Sanity Check\n",
    "print('model Consistency = ', np.mean(model_consistency))\n",
    "\n",
    "not_consistent = {i: val for i, val in enumerate(model_consistency) if val == 0}\n",
    "consistent = {i: val for i, val in enumerate(model_consistency) if val == 1}\n",
    "\n",
    "print('Number of Consistent Examples = ', len(consistent))\n",
    "print('Number of Not Consistent Examples = ', len(not_consistent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
