{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b24df6d",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"6\"><center><b> HD-CapsNet: A Hierarchical Deep Capsule Network for Image Classification </b></center></font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdcbab0",
   "metadata": {},
   "source": [
    "**Changing Model Architecture**\n",
    "- **(Mod-3.1)** 32D>16D>8D (Coarse>Medium>FINE) use skip connections between Secondary Capsules $Concatenate([P_{caps}, S_{coarse}])$ > input for $S_{medium}$ and $Concatenate([P_{caps}, S_{medium}])$ > input for $S_{fine}$\n",
    "- With $L_{Cons}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9d6d5",
   "metadata": {},
   "source": [
    "# Files and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4aa737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "# Supporting Libraries:\n",
    "    #Mathplot lib for ploting graphs\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "    # numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    #system\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "    #import other libraries\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from treelib import Tree\n",
    "    # ML model, Dataset and evalution metrics\n",
    "sys.path.append('../../') ### adding system parth for src folder\n",
    "from src import datasets # load datasets\n",
    "from src import MixUp_add_loss # load datasets\n",
    "from src import metrics # load hierarchcial metrics\n",
    "from src import sysenv # load hierarchcial metrics\n",
    "from src import models # load machine learning models\n",
    "\n",
    "    ## Tensorflow_docs\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "    # Auto reload local libraries if updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c610b",
   "metadata": {},
   "source": [
    "# System information & GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506c959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m\n",
      "• Computer Name = \u001b[0m30BFPC1AXW95\u001b[91m\u001b[1m\n",
      "• Working Directory = \u001b[0mC:\\Users\\knoor\\OneDrive - Deakin University\\Deep Learning with Python\\Google_Drive\\Projects\\Deep Learning\\HD-CapsNet\\Training_and_Analysis\\3_CIFAR-10\u001b[91m\u001b[1m\n",
      "• Python Version = \u001b[0m3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]\u001b[91m\u001b[1m\n",
      "• TensorFlow Version = \u001b[0m2.8.0\u001b[91m\u001b[1m\n",
      "• Keras Version = \u001b[0m2.8.0\u001b[91m\u001b[1m\n",
      "• Current Environment = \u001b[0mAnaconda Environment Name : py38tf\n"
     ]
    }
   ],
   "source": [
    "systeminfo = sysenv.systeminfo()\n",
    "print(systeminfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832d5a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following GPUS are selected =  0\n",
      "Done: GPU PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = \"0,1,2,3,4,5,6,7\" ## Selecting Available gpus (Multi-GPUS)\n",
    "gpus = \"0\" ## Selecting Available gpus (Single GPU)\n",
    "gpugrowth = sysenv.gpugrowth(gpus = gpus) ## Limiting GPUS from OS environment\n",
    "gpugrowth.memory_growth() #GPU memory growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3c7c5",
   "metadata": {},
   "source": [
    "## log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc9ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Folder already exist.\n"
     ]
    }
   ],
   "source": [
    "directory = sysenv.log_dir('3_CIFAR_10/HD_CapsNet/Mod_4_1_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfde972",
   "metadata": {},
   "source": [
    "# Import Dataset : CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4714d33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 dataset: Training have 50,000 samples and testing have 10,000 samples\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR10(version = 'ALL') # importing CIFAR10 Dataset\n",
    "# dataset = datasets.CIFAR10(version = 'reduce') # importing CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd551837",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b9d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"n_epochs\" : 100,\n",
    "                \"batch_size\": 64,\n",
    "                \"lr\": 0.001, # Initial learning rate\n",
    "                \"lr_decay\": 0.95, # Learning rate decay\n",
    "                \"decay_exe\": 9, #learning rate decay execution epoch after\n",
    "               }\n",
    "model_params = {\"optimizer\": tf.keras.optimizers.Adam(train_params['lr']),\n",
    "                \"loss_function\": models.MarginLoss(),\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38ee07",
   "metadata": {},
   "source": [
    "## Learning Rate Decay Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed77d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    learning_rate_init = train_params[\"lr\"]\n",
    "    \n",
    "    if epoch > train_params[\"decay_exe\"]:\n",
    "        learning_rate_init = train_params[\"lr\"] * (train_params[\"lr_decay\"] ** (epoch-9))\n",
    "        \n",
    "    tf.summary.scalar('learning rate', data=learning_rate_init, step=epoch)\n",
    "        \n",
    "    return learning_rate_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9272c71",
   "metadata": {},
   "source": [
    "# Bottom up Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d5e21",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48854261",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes_c = len(np.unique(np.argmax(dataset['y_train_coarse'], axis=1)))\n",
    "number_of_classes_m = len(np.unique(np.argmax(dataset['y_train_medium'], axis=1)))\n",
    "number_of_classes_f = len(np.unique(np.argmax(dataset['y_train_fine'], axis=1)))\n",
    "\n",
    "## For Dynamic LossWeights\n",
    "initial_lw = models.initial_lw({\"coarse\": number_of_classes_c,\n",
    "                                \"medium\": number_of_classes_m,\n",
    "                                \"fine\": number_of_classes_f})\n",
    "\n",
    "lossweight = {'coarse_lw' : K.variable(value = initial_lw['coarse'], dtype=\"float32\", name=\"coarse_lw\"),\n",
    "             'medium_lw' : K.variable(value = initial_lw['medium'], dtype=\"float32\", name=\"medium_lw\"),\n",
    "             'fine_lw' : K.variable(value = initial_lw['fine'], dtype=\"float32\", name=\"fine_lw\"),\n",
    "              'decoder_lw' : 0.1\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c021cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coarse_lw': <tf.Variable 'coarse_lw:0' shape=() dtype=float32, numpy=0.4473684>,\n",
       " 'medium_lw': <tf.Variable 'medium_lw:0' shape=() dtype=float32, numpy=0.31578946>,\n",
       " 'fine_lw': <tf.Variable 'fine_lw:0' shape=() dtype=float32, numpy=0.23684211>,\n",
       " 'decoder_lw': 0.1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256fd873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_proba):\n",
    "    y_proba = tf.math.divide(y_proba,tf.reshape(tf.reduce_sum(y_proba,-1),(-1,1),name='reshape'),name='Normalising_Probability')\n",
    "    present_error_raw = tf.square(tf.maximum(0., 0.9 - y_proba), name=\"present_error_raw\")\n",
    "    absent_error_raw = tf.square(tf.maximum(0., y_proba - 0.1), name=\"absent_error_raw\")\n",
    "    L = tf.add(y_true * present_error_raw, 0.5 * (1.0 - y_true) * absent_error_raw,name=\"L\")\n",
    "    total_marginloss = tf.reduce_sum(L, axis=1, name=\"margin_loss\")\n",
    "\n",
    "    return total_marginloss\n",
    "\n",
    "def CustomLoss(y_true_c, y_true_m, y_true_f, y_pred_c, y_pred_m, y_pred_f, LW_C, LW_M, LW_F,\n",
    "               C_Weight=lossweight['decoder_lw']):\n",
    "    # getting the loss for each level\n",
    "    loss_coarse = margin_loss(y_true_c, y_pred_c)\n",
    "    loss_medium = margin_loss(y_true_m, y_pred_m)\n",
    "    loss_fine = margin_loss(y_true_f, y_pred_f)\n",
    "\n",
    "    # Check for consistency between levels using Bayes' theorem\n",
    "    # Convert predicted probabilities to log probabilities for numerical stability\n",
    "    # coarse_predictions = 1.0-tf.reduce_sum(y_true_c*y_pred_c, axis=1)\n",
    "    # medium_predictions = 1.0-tf.reduce_sum(y_true_m*y_pred_m, axis=1)\n",
    "    # fine_predictions = 1.0-tf.reduce_sum(y_true_f*y_pred_f, axis=1)\n",
    "    prob_coarse = 1.0-loss_coarse\n",
    "    prob_medium = 1.0-loss_medium\n",
    "    prob_fine = 1.0-loss_fine\n",
    "    \n",
    "    log_pred_coarse = tf.math.log(tf.clip_by_value(prob_coarse, 1e-10, 1.0))\n",
    "    log_pred_medium = tf.math.log(tf.clip_by_value(prob_medium, 1e-10, 1.0))\n",
    "    log_pred_fine = tf.math.log(tf.clip_by_value(prob_fine, 1e-10, 1.0))\n",
    "\n",
    "    prob_fine_to_medium = tf.reduce_sum(-(log_pred_fine-log_pred_medium))\n",
    "    prob_medium_to_coarse = tf.reduce_sum(-(log_pred_medium-log_pred_coarse))\n",
    "    \n",
    "    batch_loss = LW_C*loss_coarse + LW_M*loss_medium + LW_F*loss_fine + C_Weight*(prob_fine_to_medium+prob_medium_to_coarse)\n",
    "\n",
    "    return tf.reduce_mean(batch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5ea00",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e4dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    input_shape = dataset['x_train'].shape[1:]\n",
    "\n",
    "    input_shape_yc = dataset['y_train_coarse'].shape[1:]\n",
    "    input_shape_ym = dataset['y_train_medium'].shape[1:]\n",
    "    input_shape_yf = dataset['y_train_fine'].shape[1:]\n",
    "\n",
    "    no_coarse_class = 2\n",
    "    no_medium_class = 7\n",
    "    no_fine_class = 10\n",
    "\n",
    "    PCap_n_dims = 8\n",
    "\n",
    "    SCap_f_dims = 8\n",
    "    SCap_m_dims = 16\n",
    "    SCap_c_dims = 32\n",
    "\n",
    "\n",
    "    # Input image\n",
    "    x_input = keras.layers.Input(shape=input_shape, name=\"Input_Image\")\n",
    "\n",
    "    # Input True Labels\n",
    "    y_c = keras.layers.Input(shape=input_shape_yc, name='input_yc')\n",
    "    y_m = keras.layers.Input(shape=input_shape_ym, name='input_ym')\n",
    "    y_f = keras.layers.Input(shape=input_shape_yf, name='input_yf')\n",
    "\n",
    "    #--- block 1 ---\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(x_input)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    #--- block 2 ---\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    #--- block 3 ---\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    #--- block 4 ---\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "\n",
    "    # Layer 3: Reshape to 8D primary capsules \n",
    "    reshapec = keras.layers.Reshape((int((tf.reduce_prod(x.shape[1:]).numpy())/PCap_n_dims), \n",
    "                                     PCap_n_dims), name=\"reshape_layer\")(x)\n",
    "    p_caps = keras.layers.Lambda(models.squash, name='p_caps')(reshapec)\n",
    "\n",
    "    ## Layer Secondary Capsule: For coarse level\n",
    "    s_caps_c = models.SecondaryCapsule(n_caps=no_coarse_class, n_dims=SCap_c_dims, \n",
    "                        name=\"s_caps_coarse\")(p_caps)\n",
    "    \n",
    "    ## Skip Connection: For Medium Level\n",
    "    p_caps_m = keras.layers.Reshape((int((tf.reduce_prod(p_caps.shape[1:]).numpy())/s_caps_c.shape[-1]),\n",
    "                                     s_caps_c.shape[-1]), name=\"primary_skip_m\")(p_caps)\n",
    "    skip_m = keras.layers.Concatenate(axis=1)([p_caps_m, s_caps_c])\n",
    "\n",
    "    ## Layer Secondary Capsule: For medium level\n",
    "    s_caps_m = models.SecondaryCapsule(n_caps=no_medium_class, n_dims=SCap_m_dims, \n",
    "                        name=\"s_caps_medium\")(skip_m)\n",
    "    \n",
    "    ## Skip Connection: For Fine Level\n",
    "    p_caps_f = keras.layers.Reshape((int((tf.reduce_prod(p_caps.shape[1:]).numpy())/s_caps_m.shape[-1]),\n",
    "                                     s_caps_m.shape[-1]), name=\"primary_skip_f\")(p_caps)\n",
    "    skip_f = keras.layers.Concatenate(axis=1)([p_caps_f, s_caps_m])\n",
    "\n",
    "    ## Layer Secondary Capsule: For fine level\n",
    "    s_caps_f = models.SecondaryCapsule(n_caps=no_fine_class, n_dims=SCap_f_dims, \n",
    "                        name=\"s_caps_fine\")(skip_f)\n",
    "\n",
    "    pred_c = models.LengthLayer(name='prediction_coarse')(s_caps_c)\n",
    "\n",
    "    pred_m = models.LengthLayer(name='prediction_medium')(s_caps_m)\n",
    "\n",
    "    pred_f = models.LengthLayer(name='prediction_fine')(s_caps_f)\n",
    "\n",
    "    model = keras.Model(inputs= [x_input, y_c, y_m, y_f],\n",
    "                        outputs= [pred_c, pred_m, pred_f],\n",
    "                        name='HD-CapsNet')\n",
    "    \n",
    "    ## Saving Model Architecture\n",
    "    keras.utils.plot_model(model, to_file = directory+\"/Architecture.png\", show_shapes=True)\n",
    "\n",
    "    model.add_loss(CustomLoss(y_c, y_m, y_f, pred_c, pred_m, pred_f, \n",
    "                              lossweight['coarse_lw'], lossweight['medium_lw'], lossweight['fine_lw']\n",
    "                              )\n",
    "                    )\n",
    "\n",
    "    model.compile(optimizer='adam',                  \n",
    "                  metrics={'prediction_fine': 'accuracy',\n",
    "                           'prediction_medium': 'accuracy',\n",
    "                           'prediction_coarse': 'accuracy'\n",
    "                          }\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1087df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17aadb80",
   "metadata": {},
   "source": [
    "strategy = multi_gpu_select('windows')\n",
    "\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1e4b982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HD-CapsNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_Image (InputLayer)       [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 32, 32, 64)   1792        ['Input_Image[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 64)  256         ['block1_conv1[0][0]']           \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 32, 32, 64)   36928       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['block1_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 16, 16, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 16, 16, 128)  73856       ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 128)  512        ['block2_conv1[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 16, 16, 128)  147584      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 128)  512        ['block2_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 8, 8, 128)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 8, 8, 256)    295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 256)   1024        ['block3_conv1[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 8, 8, 256)    590080      ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 256)   1024        ['block3_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 4, 4, 512)    1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 512)   2048        ['block4_conv1[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 512)   2048        ['block4_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 2, 2, 512)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape_layer (Reshape)        (None, 256, 8)       0           ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " p_caps (Lambda)                (None, 256, 8)       0           ['reshape_layer[0][0]']          \n",
      "                                                                                                  \n",
      " s_caps_coarse (SecondaryCapsul  (None, 2, 32)       131072      ['p_caps[0][0]']                 \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " primary_skip_m (Reshape)       (None, 64, 32)       0           ['p_caps[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 66, 32)       0           ['primary_skip_m[0][0]',         \n",
      "                                                                  's_caps_coarse[0][0]']          \n",
      "                                                                                                  \n",
      " s_caps_medium (SecondaryCapsul  (None, 7, 16)       236544      ['concatenate[0][0]']            \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " primary_skip_f (Reshape)       (None, 128, 16)      0           ['p_caps[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 135, 16)      0           ['primary_skip_f[0][0]',         \n",
      "                                                                  's_caps_medium[0][0]']          \n",
      "                                                                                                  \n",
      " s_caps_fine (SecondaryCapsule)  (None, 10, 8)       172800      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " input_yc (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_ym (InputLayer)          [(None, 7)]          0           []                               \n",
      "                                                                                                  \n",
      " input_yf (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " prediction_coarse (LengthLayer  (None, 2)           0           ['s_caps_coarse[0][0]']          \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " prediction_medium (LengthLayer  (None, 7)           0           ['s_caps_medium[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prediction_fine (LengthLayer)  (None, 10)           0           ['s_caps_fine[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['prediction_coarse[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_2 (TFOpLamb  (None,)             0           ['prediction_medium[0][0]']      \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_4 (TFOpLamb  (None,)             0           ['prediction_fine[0][0]']        \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1)            0           ['tf.math.reduce_sum[0][0]']     \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 1)            0           ['tf.math.reduce_sum_2[0][0]']   \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 1)            0           ['tf.math.reduce_sum_4[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.divide (TFOpLambda)    (None, 2)            0           ['prediction_coarse[0][0]',      \n",
      "                                                                  'tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.divide_1 (TFOpLambda)  (None, 7)            0           ['prediction_medium[0][0]',      \n",
      "                                                                  'tf.reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.divide_2 (TFOpLambda)  (None, 10)           0           ['prediction_fine[0][0]',        \n",
      "                                                                  'tf.reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 2)            0           ['tf.math.divide[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.math.divide[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 7)           0           ['tf.math.divide_1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLambda  (None, 7)           0           ['tf.math.divide_1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLambda  (None, 10)          0           ['tf.math.divide_2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_7 (TFOpLambda  (None, 10)          0           ['tf.math.divide_2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   (None, 2)            0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 2)           0           ['input_yc[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum_1 (TFOpLambda)  (None, 2)           0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.maximum_2 (TFOpLambda)  (None, 7)           0           ['tf.math.subtract_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLambda  (None, 7)           0           ['input_ym[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum_3 (TFOpLambda)  (None, 7)           0           ['tf.math.subtract_4[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.maximum_4 (TFOpLambda)  (None, 10)          0           ['tf.math.subtract_6[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_8 (TFOpLambda  (None, 10)          0           ['input_yf[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum_5 (TFOpLambda)  (None, 10)          0           ['tf.math.subtract_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 2)            0           ['tf.math.maximum[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 2)           0           ['tf.math.subtract_2[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.square_1 (TFOpLambda)  (None, 2)            0           ['tf.math.maximum_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.square_2 (TFOpLambda)  (None, 7)            0           ['tf.math.maximum_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 7)           0           ['tf.math.subtract_5[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.square_3 (TFOpLambda)  (None, 7)            0           ['tf.math.maximum_3[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.square_4 (TFOpLambda)  (None, 10)           0           ['tf.math.maximum_4[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 10)          0           ['tf.math.subtract_8[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.square_5 (TFOpLambda)  (None, 10)           0           ['tf.math.maximum_5[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 2)            0           ['input_yc[0][0]',               \n",
      "                                                                  'tf.math.square[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 2)           0           ['tf.math.multiply_1[0][0]',     \n",
      " )                                                                'tf.math.square_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 7)           0           ['input_ym[0][0]',               \n",
      " )                                                                'tf.math.square_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 7)           0           ['tf.math.multiply_4[0][0]',     \n",
      " )                                                                'tf.math.square_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 10)          0           ['input_yf[0][0]',               \n",
      " )                                                                'tf.math.square_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 10)          0           ['tf.math.multiply_7[0][0]',     \n",
      " )                                                                'tf.math.square_5[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)       (None, 2)            0           ['tf.math.multiply[0][0]',       \n",
      "                                                                  'tf.math.multiply_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.add_1 (TFOpLambda)     (None, 7)            0           ['tf.math.multiply_3[0][0]',     \n",
      "                                                                  'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.add_2 (TFOpLambda)     (None, 10)           0           ['tf.math.multiply_6[0][0]',     \n",
      "                                                                  'tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.add[0][0]']            \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_3 (TFOpLamb  (None,)             0           ['tf.math.add_1[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_5 (TFOpLamb  (None,)             0           ['tf.math.add_2[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.subtract_11 (TFOpLambd  (None,)             0           ['tf.math.reduce_sum_5[0][0]']   \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.subtract_10 (TFOpLambd  (None,)             0           ['tf.math.reduce_sum_3[0][0]']   \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.subtract_9 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_1[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.clip_by_value_2 (TFOpLambda  (None,)             0           ['tf.math.subtract_11[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.clip_by_value_1 (TFOpLambda  (None,)             0           ['tf.math.subtract_10[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.clip_by_value (TFOpLambda)  (None,)              0           ['tf.math.subtract_9[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.log_2 (TFOpLambda)     (None,)              0           ['tf.clip_by_value_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.log_1 (TFOpLambda)     (None,)              0           ['tf.clip_by_value_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.log (TFOpLambda)       (None,)              0           ['tf.clip_by_value[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_12 (TFOpLambd  (None,)             0           ['tf.math.log_2[0][0]',          \n",
      " a)                                                               'tf.math.log_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.subtract_13 (TFOpLambd  (None,)             0           ['tf.math.log_1[0][0]',          \n",
      " a)                                                               'tf.math.log[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.negative (TFOpLambda)  (None,)              0           ['tf.math.subtract_12[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.negative_1 (TFOpLambda  (None,)             0           ['tf.math.subtract_13[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_1[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None,)             0           ['tf.math.reduce_sum_3[0][0]']   \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_6 (TFOpLamb  ()                  0           ['tf.math.negative[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_7 (TFOpLamb  ()                  0           ['tf.math.negative_1[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None,)             0           ['tf.math.multiply_9[0][0]',     \n",
      " da)                                                              'tf.math.multiply_10[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None,)             0           ['tf.math.reduce_sum_5[0][0]']   \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_sum_6[0][0]',   \n",
      " mbda)                                                            'tf.math.reduce_sum_7[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.__operators__.add[0][0]',   \n",
      " mbda)                                                            'tf.math.multiply_11[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  ()                  0           ['tf.__operators__.add_2[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None,)             0           ['tf.__operators__.add_1[0][0]', \n",
      " mbda)                                                            'tf.math.multiply_12[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.__operators__.add_3[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,233,472\n",
      "Trainable params: 5,229,632\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f72ece",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "\n",
    "training_generator = MixUp_add_loss.MixupGenerator_3level(dataset['x_train'],\n",
    "                                                 dataset['y_train_coarse'], \n",
    "                                                 dataset['y_train_medium'],\n",
    "                                                 dataset['y_train_fine'],\n",
    "                                                 batch_size=train_params[\"batch_size\"],\n",
    "                                                 alpha=0.2, \n",
    "                                                 datagen=datagen\n",
    "                                                )()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67d719",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0a123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = keras.callbacks.TensorBoard(directory+'./tb_logs'+ datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "log = keras.callbacks.CSVLogger(directory+'/log.csv', append=True)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    directory+'/epoch-best.h5', \n",
    "    monitor='val_prediction_fine_accuracy',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "change_lw = models.LossWeightsModifier(lossweight = lossweight,\n",
    "                               initial_lw = initial_lw,\n",
    "                               directory = directory)\n",
    "lr_decay = keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc176a2",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a48f8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: 2.6292 - prediction_coarse_accuracy: 0.2532 - prediction_medium_accuracy: 0.5352 - prediction_fine_accuracy: 0.4527\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 25.31% | Val_Accuracy = 14.32% | LossWeight = 0.49 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 53.52% | Val_Accuracy = 66.26% | LossWeight = 0.22 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 45.28% | Val_Accuracy = 57.97% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 1: val_prediction_fine_accuracy improved from -inf to 0.57970, saving model to ../../logs/3_CIFAR_10/HD_CapsNet/Mod_4_1_2\\epoch-best.h5\n",
      "781/781 [==============================] - 48s 51ms/step - loss: 2.6288 - prediction_coarse_accuracy: 0.2531 - prediction_medium_accuracy: 0.5352 - prediction_fine_accuracy: 0.4528 - val_loss: 1.1481 - val_prediction_coarse_accuracy: 0.1432 - val_prediction_medium_accuracy: 0.6626 - val_prediction_fine_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: 1.7026 - prediction_coarse_accuracy: 0.1308 - prediction_medium_accuracy: 0.7038 - prediction_fine_accuracy: 0.6214\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 13.07% | Val_Accuracy = 8.63% | LossWeight = 0.61 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 70.38% | Val_Accuracy = 74.25% | LossWeight = 0.15 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.14% | Val_Accuracy = 65.08% | LossWeight = 0.14 \u001b[0m\n",
      "\n",
      "Epoch 2: val_prediction_fine_accuracy improved from 0.57970 to 0.65080, saving model to ../../logs/3_CIFAR_10/HD_CapsNet/Mod_4_1_2\\epoch-best.h5\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 1.7022 - prediction_coarse_accuracy: 0.1307 - prediction_medium_accuracy: 0.7038 - prediction_fine_accuracy: 0.6214 - val_loss: 0.8145 - val_prediction_coarse_accuracy: 0.0863 - val_prediction_medium_accuracy: 0.7425 - val_prediction_fine_accuracy: 0.6508 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.1010 - prediction_coarse_accuracy: 0.0817 - prediction_medium_accuracy: 0.7652 - prediction_fine_accuracy: 0.7049\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 8.17% | Val_Accuracy = 4.28% | LossWeight = 0.67 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 76.52% | Val_Accuracy = 80.27% | LossWeight = 0.12 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 70.49% | Val_Accuracy = 73.16% | LossWeight = 0.11 \u001b[0m\n",
      "\n",
      "Epoch 3: val_prediction_fine_accuracy improved from 0.65080 to 0.73160, saving model to ../../logs/3_CIFAR_10/HD_CapsNet/Mod_4_1_2\\epoch-best.h5\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1010 - prediction_coarse_accuracy: 0.0817 - prediction_medium_accuracy: 0.7652 - prediction_fine_accuracy: 0.7049 - val_loss: 0.5249 - val_prediction_coarse_accuracy: 0.0428 - val_prediction_medium_accuracy: 0.8027 - val_prediction_fine_accuracy: 0.7316 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -42.8666 - prediction_coarse_accuracy: 0.3779 - prediction_medium_accuracy: 0.3018 - prediction_fine_accuracy: 0.2222\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 37.80% | Val_Accuracy = 38.51% | LossWeight = 0.37 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 30.18% | Val_Accuracy = 30.63% | LossWeight = 0.29 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 22.22% | Val_Accuracy = 24.83% | LossWeight = 0.24 \u001b[0m\n",
      "\n",
      "Epoch 4: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -42.8884 - prediction_coarse_accuracy: 0.3780 - prediction_medium_accuracy: 0.3018 - prediction_fine_accuracy: 0.2222 - val_loss: -39.4570 - val_prediction_coarse_accuracy: 0.3851 - val_prediction_medium_accuracy: 0.3063 - val_prediction_fine_accuracy: 0.2483 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -72.6261 - prediction_coarse_accuracy: 0.3891 - prediction_medium_accuracy: 0.3624 - prediction_fine_accuracy: 0.2756\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 38.92% | Val_Accuracy = 39.07% | LossWeight = 0.38 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 36.25% | Val_Accuracy = 44.21% | LossWeight = 0.28 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 27.57% | Val_Accuracy = 36.25% | LossWeight = 0.24 \u001b[0m\n",
      "\n",
      "Epoch 5: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -72.6196 - prediction_coarse_accuracy: 0.3892 - prediction_medium_accuracy: 0.3625 - prediction_fine_accuracy: 0.2757 - val_loss: -40.4642 - val_prediction_coarse_accuracy: 0.3907 - val_prediction_medium_accuracy: 0.4421 - val_prediction_fine_accuracy: 0.3625 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -70.0381 - prediction_coarse_accuracy: 0.3953 - prediction_medium_accuracy: 0.3799 - prediction_fine_accuracy: 0.2859\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.55% | Val_Accuracy = 40.00% | LossWeight = 0.38 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 38.00% | Val_Accuracy = 42.39% | LossWeight = 0.28 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 28.59% | Val_Accuracy = 33.68% | LossWeight = 0.24 \u001b[0m\n",
      "\n",
      "Epoch 6: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -70.0284 - prediction_coarse_accuracy: 0.3955 - prediction_medium_accuracy: 0.3800 - prediction_fine_accuracy: 0.2859 - val_loss: -40.5376 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.4239 - val_prediction_fine_accuracy: 0.3368 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -72.8620 - prediction_coarse_accuracy: 0.3998 - prediction_medium_accuracy: 0.4289 - prediction_fine_accuracy: 0.3273\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.97% | Val_Accuracy = 40.00% | LossWeight = 0.40 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 42.89% | Val_Accuracy = 47.98% | LossWeight = 0.27 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 32.72% | Val_Accuracy = 39.65% | LossWeight = 0.24 \u001b[0m\n",
      "\n",
      "Epoch 7: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -72.8628 - prediction_coarse_accuracy: 0.3997 - prediction_medium_accuracy: 0.4289 - prediction_fine_accuracy: 0.3272 - val_loss: -40.8412 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.4798 - val_prediction_fine_accuracy: 0.3965 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -72.9807 - prediction_coarse_accuracy: 0.4009 - prediction_medium_accuracy: 0.4404 - prediction_fine_accuracy: 0.3400\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.09% | Val_Accuracy = 40.00% | LossWeight = 0.40 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 44.04% | Val_Accuracy = 46.47% | LossWeight = 0.26 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 34.00% | Val_Accuracy = 38.25% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 8: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -72.9807 - prediction_coarse_accuracy: 0.4009 - prediction_medium_accuracy: 0.4404 - prediction_fine_accuracy: 0.3400 - val_loss: -40.7704 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.4647 - val_prediction_fine_accuracy: 0.3825 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -74.1732 - prediction_coarse_accuracy: 0.4001 - prediction_medium_accuracy: 0.4627 - prediction_fine_accuracy: 0.3634\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.01% | Val_Accuracy = 40.00% | LossWeight = 0.41 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 46.27% | Val_Accuracy = 49.98% | LossWeight = 0.26 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 36.34% | Val_Accuracy = 40.81% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 9: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -74.1732 - prediction_coarse_accuracy: 0.4001 - prediction_medium_accuracy: 0.4627 - prediction_fine_accuracy: 0.3634 - val_loss: -40.9676 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.4998 - val_prediction_fine_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -74.3075 - prediction_coarse_accuracy: 0.4024 - prediction_medium_accuracy: 0.4820 - prediction_fine_accuracy: 0.3849\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.24% | Val_Accuracy = 40.00% | LossWeight = 0.42 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 48.20% | Val_Accuracy = 51.30% | LossWeight = 0.26 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 38.49% | Val_Accuracy = 43.63% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 10: val_prediction_fine_accuracy did not improve from 0.73160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 35s 45ms/step - loss: -74.3075 - prediction_coarse_accuracy: 0.4024 - prediction_medium_accuracy: 0.4820 - prediction_fine_accuracy: 0.3849 - val_loss: -41.0269 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5130 - val_prediction_fine_accuracy: 0.4363 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -74.4064 - prediction_coarse_accuracy: 0.4014 - prediction_medium_accuracy: 0.4870 - prediction_fine_accuracy: 0.3921\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.12% | Val_Accuracy = 40.00% | LossWeight = 0.42 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 48.71% | Val_Accuracy = 53.72% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 39.21% | Val_Accuracy = 44.41% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 11: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -74.4356 - prediction_coarse_accuracy: 0.4012 - prediction_medium_accuracy: 0.4871 - prediction_fine_accuracy: 0.3921 - val_loss: -41.1285 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5372 - val_prediction_fine_accuracy: 0.4441 - lr: 9.5000e-04\n",
      "Epoch 12/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -74.1161 - prediction_coarse_accuracy: 0.3986 - prediction_medium_accuracy: 0.4936 - prediction_fine_accuracy: 0.4005\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.85% | Val_Accuracy = 40.00% | LossWeight = 0.42 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 49.35% | Val_Accuracy = 37.20% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 40.01% | Val_Accuracy = 26.37% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 12: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 35s 45ms/step - loss: -74.1185 - prediction_coarse_accuracy: 0.3985 - prediction_medium_accuracy: 0.4935 - prediction_fine_accuracy: 0.4001 - val_loss: -40.2950 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.3720 - val_prediction_fine_accuracy: 0.2637 - lr: 9.0250e-04\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -69.8602 - prediction_coarse_accuracy: 0.4024 - prediction_medium_accuracy: 0.4640 - prediction_fine_accuracy: 0.3663\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.24% | Val_Accuracy = 40.00% | LossWeight = 0.41 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 46.40% | Val_Accuracy = 51.11% | LossWeight = 0.26 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 36.63% | Val_Accuracy = 42.14% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 13: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -69.8602 - prediction_coarse_accuracy: 0.4024 - prediction_medium_accuracy: 0.4640 - prediction_fine_accuracy: 0.3663 - val_loss: -40.9614 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5111 - val_prediction_fine_accuracy: 0.4214 - lr: 8.5737e-04\n",
      "Epoch 14/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -71.5093 - prediction_coarse_accuracy: 0.4011 - prediction_medium_accuracy: 0.4852 - prediction_fine_accuracy: 0.3932\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.11% | Val_Accuracy = 40.00% | LossWeight = 0.42 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 48.52% | Val_Accuracy = 53.89% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 39.33% | Val_Accuracy = 44.43% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 14: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -71.5052 - prediction_coarse_accuracy: 0.4011 - prediction_medium_accuracy: 0.4852 - prediction_fine_accuracy: 0.3933 - val_loss: -40.1216 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5389 - val_prediction_fine_accuracy: 0.4443 - lr: 8.1451e-04\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -72.0630 - prediction_coarse_accuracy: 0.4018 - prediction_medium_accuracy: 0.4864 - prediction_fine_accuracy: 0.3916\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.18% | Val_Accuracy = 40.00% | LossWeight = 0.42 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 48.64% | Val_Accuracy = 46.71% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 39.16% | Val_Accuracy = 37.38% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 15: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 34s 44ms/step - loss: -72.0630 - prediction_coarse_accuracy: 0.4018 - prediction_medium_accuracy: 0.4864 - prediction_fine_accuracy: 0.3916 - val_loss: -40.9086 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.4671 - val_prediction_fine_accuracy: 0.3738 - lr: 7.7378e-04\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -72.7836 - prediction_coarse_accuracy: 0.4030 - prediction_medium_accuracy: 0.4728 - prediction_fine_accuracy: 0.3723\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.30% | Val_Accuracy = 40.00% | LossWeight = 0.41 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 47.28% | Val_Accuracy = 52.22% | LossWeight = 0.26 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 37.23% | Val_Accuracy = 42.59% | LossWeight = 0.23 \u001b[0m\n",
      "\n",
      "Epoch 16: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -72.7836 - prediction_coarse_accuracy: 0.4030 - prediction_medium_accuracy: 0.4728 - prediction_fine_accuracy: 0.3723 - val_loss: -40.4650 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5222 - val_prediction_fine_accuracy: 0.4259 - lr: 7.3509e-04\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -74.1088 - prediction_coarse_accuracy: 0.3984 - prediction_medium_accuracy: 0.4972 - prediction_fine_accuracy: 0.3981\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.84% | Val_Accuracy = 40.00% | LossWeight = 0.42 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 49.72% | Val_Accuracy = 52.26% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 39.81% | Val_Accuracy = 43.74% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 17: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -74.1088 - prediction_coarse_accuracy: 0.3984 - prediction_medium_accuracy: 0.4972 - prediction_fine_accuracy: 0.3981 - val_loss: -40.8273 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5226 - val_prediction_fine_accuracy: 0.4374 - lr: 6.9834e-04\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -74.5791 - prediction_coarse_accuracy: 0.4002 - prediction_medium_accuracy: 0.5037 - prediction_fine_accuracy: 0.4041\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.02% | Val_Accuracy = 40.00% | LossWeight = 0.43 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 50.37% | Val_Accuracy = 53.38% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 40.41% | Val_Accuracy = 44.57% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 18: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -74.5791 - prediction_coarse_accuracy: 0.4002 - prediction_medium_accuracy: 0.5037 - prediction_fine_accuracy: 0.4041 - val_loss: -41.0469 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5338 - val_prediction_fine_accuracy: 0.4457 - lr: 6.6342e-04\n",
      "Epoch 19/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -74.2033 - prediction_coarse_accuracy: 0.4021 - prediction_medium_accuracy: 0.5087 - prediction_fine_accuracy: 0.4108\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.21% | Val_Accuracy = 40.00% | LossWeight = 0.43 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 50.87% | Val_Accuracy = 55.55% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 41.07% | Val_Accuracy = 46.75% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 19: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -74.2006 - prediction_coarse_accuracy: 0.4021 - prediction_medium_accuracy: 0.5087 - prediction_fine_accuracy: 0.4107 - val_loss: -41.2563 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5555 - val_prediction_fine_accuracy: 0.4675 - lr: 6.3025e-04\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -74.0416 - prediction_coarse_accuracy: 0.3980 - prediction_medium_accuracy: 0.5091 - prediction_fine_accuracy: 0.4149\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.80% | Val_Accuracy = 40.00% | LossWeight = 0.43 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 50.91% | Val_Accuracy = 55.99% | LossWeight = 0.25 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 41.49% | Val_Accuracy = 46.67% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 20: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -74.0416 - prediction_coarse_accuracy: 0.3980 - prediction_medium_accuracy: 0.5091 - prediction_fine_accuracy: 0.4149 - val_loss: -41.1241 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5599 - val_prediction_fine_accuracy: 0.4667 - lr: 5.9874e-04\n",
      "Epoch 21/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -74.3376 - prediction_coarse_accuracy: 0.4016 - prediction_medium_accuracy: 0.5215 - prediction_fine_accuracy: 0.4246\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.15% | Val_Accuracy = 40.00% | LossWeight = 0.43 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 52.16% | Val_Accuracy = 54.97% | LossWeight = 0.24 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 42.46% | Val_Accuracy = 45.80% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 21: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -74.3263 - prediction_coarse_accuracy: 0.4015 - prediction_medium_accuracy: 0.5216 - prediction_fine_accuracy: 0.4246 - val_loss: -41.1975 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5497 - val_prediction_fine_accuracy: 0.4580 - lr: 5.6880e-04\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -75.0303 - prediction_coarse_accuracy: 0.4007 - prediction_medium_accuracy: 0.5454 - prediction_fine_accuracy: 0.4504\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.07% | Val_Accuracy = 40.00% | LossWeight = 0.45 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 54.54% | Val_Accuracy = 58.48% | LossWeight = 0.24 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 45.04% | Val_Accuracy = 50.17% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 22: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -75.0303 - prediction_coarse_accuracy: 0.4007 - prediction_medium_accuracy: 0.5454 - prediction_fine_accuracy: 0.4504 - val_loss: -41.4588 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5848 - val_prediction_fine_accuracy: 0.5017 - lr: 5.4036e-04\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -74.7205 - prediction_coarse_accuracy: 0.4034 - prediction_medium_accuracy: 0.5507 - prediction_fine_accuracy: 0.4562\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.34% | Val_Accuracy = 40.00% | LossWeight = 0.45 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 55.07% | Val_Accuracy = 57.13% | LossWeight = 0.24 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 45.62% | Val_Accuracy = 49.51% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 23: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -74.7205 - prediction_coarse_accuracy: 0.4034 - prediction_medium_accuracy: 0.5507 - prediction_fine_accuracy: 0.4562 - val_loss: -41.2091 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5713 - val_prediction_fine_accuracy: 0.4951 - lr: 5.1334e-04\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -74.6032 - prediction_coarse_accuracy: 0.4022 - prediction_medium_accuracy: 0.5444 - prediction_fine_accuracy: 0.4503\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.22% | Val_Accuracy = 40.00% | LossWeight = 0.44 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 54.44% | Val_Accuracy = 59.82% | LossWeight = 0.24 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 45.03% | Val_Accuracy = 51.47% | LossWeight = 0.22 \u001b[0m\n",
      "\n",
      "Epoch 24: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 43ms/step - loss: -74.6032 - prediction_coarse_accuracy: 0.4022 - prediction_medium_accuracy: 0.5444 - prediction_fine_accuracy: 0.4503 - val_loss: -41.5739 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5982 - val_prediction_fine_accuracy: 0.5147 - lr: 4.8767e-04\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -75.0859 - prediction_coarse_accuracy: 0.4009 - prediction_medium_accuracy: 0.5634 - prediction_fine_accuracy: 0.4727\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.09% | Val_Accuracy = 40.00% | LossWeight = 0.45 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 56.34% | Val_Accuracy = 61.46% | LossWeight = 0.23 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 47.27% | Val_Accuracy = 52.41% | LossWeight = 0.21 \u001b[0m\n",
      "\n",
      "Epoch 25: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 43ms/step - loss: -75.0859 - prediction_coarse_accuracy: 0.4009 - prediction_medium_accuracy: 0.5634 - prediction_fine_accuracy: 0.4727 - val_loss: -41.6687 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6146 - val_prediction_fine_accuracy: 0.5241 - lr: 4.6329e-04\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -75.2525 - prediction_coarse_accuracy: 0.4026 - prediction_medium_accuracy: 0.5766 - prediction_fine_accuracy: 0.4890\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.26% | Val_Accuracy = 40.00% | LossWeight = 0.46 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 57.66% | Val_Accuracy = 62.11% | LossWeight = 0.23 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 48.90% | Val_Accuracy = 53.61% | LossWeight = 0.21 \u001b[0m\n",
      "\n",
      "Epoch 26: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -75.2525 - prediction_coarse_accuracy: 0.4026 - prediction_medium_accuracy: 0.5766 - prediction_fine_accuracy: 0.4890 - val_loss: -41.7690 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6211 - val_prediction_fine_accuracy: 0.5361 - lr: 4.4013e-04\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.0544 - prediction_coarse_accuracy: 0.3994 - prediction_medium_accuracy: 0.5868 - prediction_fine_accuracy: 0.5001\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.94% | Val_Accuracy = 40.00% | LossWeight = 0.47 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 58.68% | Val_Accuracy = 63.71% | LossWeight = 0.23 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 50.01% | Val_Accuracy = 54.93% | LossWeight = 0.21 \u001b[0m\n",
      "\n",
      "Epoch 27: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -76.0544 - prediction_coarse_accuracy: 0.3994 - prediction_medium_accuracy: 0.5868 - prediction_fine_accuracy: 0.5001 - val_loss: -41.8572 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6371 - val_prediction_fine_accuracy: 0.5493 - lr: 4.1812e-04\n",
      "Epoch 28/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.0706 - prediction_coarse_accuracy: 0.3966 - prediction_medium_accuracy: 0.5898 - prediction_fine_accuracy: 0.5017\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.67% | Val_Accuracy = 40.00% | LossWeight = 0.47 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 58.99% | Val_Accuracy = 62.70% | LossWeight = 0.23 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 50.18% | Val_Accuracy = 53.96% | LossWeight = 0.21 \u001b[0m\n",
      "\n",
      "Epoch 28: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -76.0694 - prediction_coarse_accuracy: 0.3967 - prediction_medium_accuracy: 0.5899 - prediction_fine_accuracy: 0.5018 - val_loss: -41.6932 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6270 - val_prediction_fine_accuracy: 0.5396 - lr: 3.9721e-04\n",
      "Epoch 29/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -75.5161 - prediction_coarse_accuracy: 0.3995 - prediction_medium_accuracy: 0.5989 - prediction_fine_accuracy: 0.5080\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.94% | Val_Accuracy = 40.00% | LossWeight = 0.47 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 59.88% | Val_Accuracy = 58.85% | LossWeight = 0.22 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 50.79% | Val_Accuracy = 50.35% | LossWeight = 0.20 \u001b[0m\n",
      "\n",
      "Epoch 29: val_prediction_fine_accuracy did not improve from 0.73160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 33s 42ms/step - loss: -75.5253 - prediction_coarse_accuracy: 0.3994 - prediction_medium_accuracy: 0.5988 - prediction_fine_accuracy: 0.5079 - val_loss: -41.6344 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.5885 - val_prediction_fine_accuracy: 0.5035 - lr: 3.7735e-04\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -75.0141 - prediction_coarse_accuracy: 0.4027 - prediction_medium_accuracy: 0.5986 - prediction_fine_accuracy: 0.5084\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.27% | Val_Accuracy = 40.00% | LossWeight = 0.47 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 59.86% | Val_Accuracy = 62.29% | LossWeight = 0.22 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 50.84% | Val_Accuracy = 54.50% | LossWeight = 0.21 \u001b[0m\n",
      "\n",
      "Epoch 30: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 42ms/step - loss: -75.0141 - prediction_coarse_accuracy: 0.4027 - prediction_medium_accuracy: 0.5986 - prediction_fine_accuracy: 0.5084 - val_loss: -41.6700 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6229 - val_prediction_fine_accuracy: 0.5450 - lr: 3.5849e-04\n",
      "Epoch 31/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.1971 - prediction_coarse_accuracy: 0.3993 - prediction_medium_accuracy: 0.6197 - prediction_fine_accuracy: 0.5352\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.94% | Val_Accuracy = 40.00% | LossWeight = 0.48 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 61.98% | Val_Accuracy = 65.48% | LossWeight = 0.22 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 53.53% | Val_Accuracy = 57.37% | LossWeight = 0.20 \u001b[0m\n",
      "\n",
      "Epoch 31: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 43ms/step - loss: -76.1895 - prediction_coarse_accuracy: 0.3994 - prediction_medium_accuracy: 0.6198 - prediction_fine_accuracy: 0.5353 - val_loss: -41.8464 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6548 - val_prediction_fine_accuracy: 0.5737 - lr: 3.4056e-04\n",
      "Epoch 32/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -75.8128 - prediction_coarse_accuracy: 0.4014 - prediction_medium_accuracy: 0.6230 - prediction_fine_accuracy: 0.5357\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.15% | Val_Accuracy = 40.00% | LossWeight = 0.49 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 62.31% | Val_Accuracy = 65.14% | LossWeight = 0.22 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 53.58% | Val_Accuracy = 57.68% | LossWeight = 0.20 \u001b[0m\n",
      "\n",
      "Epoch 32: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 35s 45ms/step - loss: -75.7980 - prediction_coarse_accuracy: 0.4015 - prediction_medium_accuracy: 0.6231 - prediction_fine_accuracy: 0.5358 - val_loss: -41.7243 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6514 - val_prediction_fine_accuracy: 0.5768 - lr: 3.2353e-04\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -75.9140 - prediction_coarse_accuracy: 0.4009 - prediction_medium_accuracy: 0.6277 - prediction_fine_accuracy: 0.5440\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.09% | Val_Accuracy = 39.98% | LossWeight = 0.49 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 62.77% | Val_Accuracy = 61.21% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 54.40% | Val_Accuracy = 51.38% | LossWeight = 0.20 \u001b[0m\n",
      "\n",
      "Epoch 33: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 41s 53ms/step - loss: -75.9140 - prediction_coarse_accuracy: 0.4009 - prediction_medium_accuracy: 0.6277 - prediction_fine_accuracy: 0.5440 - val_loss: -41.5354 - val_prediction_coarse_accuracy: 0.3998 - val_prediction_medium_accuracy: 0.6121 - val_prediction_fine_accuracy: 0.5138 - lr: 3.0736e-04\n",
      "Epoch 34/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.3490 - prediction_coarse_accuracy: 0.3987 - prediction_medium_accuracy: 0.6189 - prediction_fine_accuracy: 0.5363\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.87% | Val_Accuracy = 40.00% | LossWeight = 0.49 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 61.90% | Val_Accuracy = 66.28% | LossWeight = 0.22 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 53.63% | Val_Accuracy = 58.26% | LossWeight = 0.20 \u001b[0m\n",
      "\n",
      "Epoch 34: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 38s 49ms/step - loss: -76.3616 - prediction_coarse_accuracy: 0.3987 - prediction_medium_accuracy: 0.6190 - prediction_fine_accuracy: 0.5363 - val_loss: -41.9534 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6628 - val_prediction_fine_accuracy: 0.5826 - lr: 2.9199e-04\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.4461 - prediction_coarse_accuracy: 0.3977 - prediction_medium_accuracy: 0.6361 - prediction_fine_accuracy: 0.5529\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.77% | Val_Accuracy = 40.00% | LossWeight = 0.49 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 63.61% | Val_Accuracy = 64.34% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 55.29% | Val_Accuracy = 56.74% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 35: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 33s 43ms/step - loss: -76.4461 - prediction_coarse_accuracy: 0.3977 - prediction_medium_accuracy: 0.6361 - prediction_fine_accuracy: 0.5529 - val_loss: -41.6651 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6434 - val_prediction_fine_accuracy: 0.5674 - lr: 2.7739e-04\n",
      "Epoch 36/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.0260 - prediction_coarse_accuracy: 0.4016 - prediction_medium_accuracy: 0.6357 - prediction_fine_accuracy: 0.5526\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.17% | Val_Accuracy = 40.00% | LossWeight = 0.49 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 63.57% | Val_Accuracy = 62.73% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 55.26% | Val_Accuracy = 54.22% | LossWeight = 0.20 \u001b[0m\n",
      "\n",
      "Epoch 36: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 35s 45ms/step - loss: -75.9998 - prediction_coarse_accuracy: 0.4017 - prediction_medium_accuracy: 0.6357 - prediction_fine_accuracy: 0.5526 - val_loss: -41.6447 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6273 - val_prediction_fine_accuracy: 0.5422 - lr: 2.6352e-04\n",
      "Epoch 37/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -75.8470 - prediction_coarse_accuracy: 0.4008 - prediction_medium_accuracy: 0.6364 - prediction_fine_accuracy: 0.5557\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.08% | Val_Accuracy = 40.00% | LossWeight = 0.49 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 63.65% | Val_Accuracy = 67.24% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 55.57% | Val_Accuracy = 59.23% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 37: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -75.8444 - prediction_coarse_accuracy: 0.4008 - prediction_medium_accuracy: 0.6365 - prediction_fine_accuracy: 0.5557 - val_loss: -41.7354 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6724 - val_prediction_fine_accuracy: 0.5923 - lr: 2.5034e-04\n",
      "Epoch 38/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -75.9608 - prediction_coarse_accuracy: 0.4004 - prediction_medium_accuracy: 0.6043 - prediction_fine_accuracy: 0.5208\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.04% | Val_Accuracy = 40.00% | LossWeight = 0.48 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 60.45% | Val_Accuracy = 65.17% | LossWeight = 0.22 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 52.10% | Val_Accuracy = 57.30% | LossWeight = 0.20 \u001b[0m\n",
      "\n",
      "Epoch 38: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -75.9543 - prediction_coarse_accuracy: 0.4004 - prediction_medium_accuracy: 0.6045 - prediction_fine_accuracy: 0.5210 - val_loss: -41.6360 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6517 - val_prediction_fine_accuracy: 0.5730 - lr: 2.3783e-04\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.5484 - prediction_coarse_accuracy: 0.3979 - prediction_medium_accuracy: 0.6389 - prediction_fine_accuracy: 0.5579\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.79% | Val_Accuracy = 40.00% | LossWeight = 0.50 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 63.89% | Val_Accuracy = 67.69% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 55.79% | Val_Accuracy = 59.27% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 39: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -76.5484 - prediction_coarse_accuracy: 0.3979 - prediction_medium_accuracy: 0.6389 - prediction_fine_accuracy: 0.5579 - val_loss: -41.8638 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6769 - val_prediction_fine_accuracy: 0.5927 - lr: 2.2594e-04\n",
      "Epoch 40/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.3671 - prediction_coarse_accuracy: 0.4004 - prediction_medium_accuracy: 0.6499 - prediction_fine_accuracy: 0.5708\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.02% | Val_Accuracy = 40.00% | LossWeight = 0.50 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 64.98% | Val_Accuracy = 66.89% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 57.07% | Val_Accuracy = 59.25% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 40: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 47ms/step - loss: -76.3796 - prediction_coarse_accuracy: 0.4002 - prediction_medium_accuracy: 0.6498 - prediction_fine_accuracy: 0.5707 - val_loss: -41.8534 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6689 - val_prediction_fine_accuracy: 0.5925 - lr: 2.1464e-04\n",
      "Epoch 41/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.0012 - prediction_coarse_accuracy: 0.4023 - prediction_medium_accuracy: 0.6577 - prediction_fine_accuracy: 0.5802\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.22% | Val_Accuracy = 40.00% | LossWeight = 0.51 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 65.76% | Val_Accuracy = 67.26% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 58.00% | Val_Accuracy = 57.44% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 41: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -76.0207 - prediction_coarse_accuracy: 0.4022 - prediction_medium_accuracy: 0.6576 - prediction_fine_accuracy: 0.5800 - val_loss: -41.6736 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6726 - val_prediction_fine_accuracy: 0.5744 - lr: 2.0391e-04\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.2826 - prediction_coarse_accuracy: 0.4029 - prediction_medium_accuracy: 0.6566 - prediction_fine_accuracy: 0.5777\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.29% | Val_Accuracy = 40.00% | LossWeight = 0.51 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 65.66% | Val_Accuracy = 66.10% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 57.77% | Val_Accuracy = 58.39% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 42: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -76.2826 - prediction_coarse_accuracy: 0.4029 - prediction_medium_accuracy: 0.6566 - prediction_fine_accuracy: 0.5777 - val_loss: -41.8576 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6610 - val_prediction_fine_accuracy: 0.5839 - lr: 1.9371e-04\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.9042 - prediction_coarse_accuracy: 0.3975 - prediction_medium_accuracy: 0.6550 - prediction_fine_accuracy: 0.5791\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.75% | Val_Accuracy = 40.00% | LossWeight = 0.51 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 65.50% | Val_Accuracy = 68.49% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 57.91% | Val_Accuracy = 61.27% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 43: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 47ms/step - loss: -76.9042 - prediction_coarse_accuracy: 0.3975 - prediction_medium_accuracy: 0.6550 - prediction_fine_accuracy: 0.5791 - val_loss: -42.0448 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6849 - val_prediction_fine_accuracy: 0.6127 - lr: 1.8403e-04\n",
      "Epoch 44/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.6391 - prediction_coarse_accuracy: 0.3989 - prediction_medium_accuracy: 0.6550 - prediction_fine_accuracy: 0.5794\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.89% | Val_Accuracy = 40.00% | LossWeight = 0.51 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 65.51% | Val_Accuracy = 65.61% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 57.94% | Val_Accuracy = 57.74% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 44: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 47ms/step - loss: -76.6375 - prediction_coarse_accuracy: 0.3989 - prediction_medium_accuracy: 0.6551 - prediction_fine_accuracy: 0.5794 - val_loss: -41.8874 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6561 - val_prediction_fine_accuracy: 0.5774 - lr: 1.7482e-04\n",
      "Epoch 45/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.4859 - prediction_coarse_accuracy: 0.4005 - prediction_medium_accuracy: 0.6528 - prediction_fine_accuracy: 0.5774\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.05% | Val_Accuracy = 40.00% | LossWeight = 0.51 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 65.28% | Val_Accuracy = 68.36% | LossWeight = 0.21 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 57.74% | Val_Accuracy = 60.94% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 45: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -76.4758 - prediction_coarse_accuracy: 0.4005 - prediction_medium_accuracy: 0.6528 - prediction_fine_accuracy: 0.5774 - val_loss: -41.9377 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6836 - val_prediction_fine_accuracy: 0.6094 - lr: 1.6608e-04\n",
      "Epoch 46/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.7769 - prediction_coarse_accuracy: 0.3996 - prediction_medium_accuracy: 0.6696 - prediction_fine_accuracy: 0.5920\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.95% | Val_Accuracy = 39.94% | LossWeight = 0.51 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 66.96% | Val_Accuracy = 69.48% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 59.19% | Val_Accuracy = 61.81% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 46: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -76.7790 - prediction_coarse_accuracy: 0.3995 - prediction_medium_accuracy: 0.6696 - prediction_fine_accuracy: 0.5919 - val_loss: -42.0628 - val_prediction_coarse_accuracy: 0.3994 - val_prediction_medium_accuracy: 0.6948 - val_prediction_fine_accuracy: 0.6181 - lr: 1.5778e-04\n",
      "Epoch 47/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.7545 - prediction_coarse_accuracy: 0.3990 - prediction_medium_accuracy: 0.6726 - prediction_fine_accuracy: 0.5977\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.88% | Val_Accuracy = 39.56% | LossWeight = 0.52 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 67.27% | Val_Accuracy = 68.98% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 59.77% | Val_Accuracy = 61.77% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 47: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 47ms/step - loss: -76.7711 - prediction_coarse_accuracy: 0.3988 - prediction_medium_accuracy: 0.6727 - prediction_fine_accuracy: 0.5977 - val_loss: -42.0396 - val_prediction_coarse_accuracy: 0.3956 - val_prediction_medium_accuracy: 0.6898 - val_prediction_fine_accuracy: 0.6177 - lr: 1.4989e-04\n",
      "Epoch 48/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -77.1077 - prediction_coarse_accuracy: 0.3962 - prediction_medium_accuracy: 0.6628 - prediction_fine_accuracy: 0.5850\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.62% | Val_Accuracy = 39.97% | LossWeight = 0.51 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 66.28% | Val_Accuracy = 69.69% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 58.50% | Val_Accuracy = 62.07% | LossWeight = 0.19 \u001b[0m\n",
      "\n",
      "Epoch 48: val_prediction_fine_accuracy did not improve from 0.73160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 36s 46ms/step - loss: -77.1033 - prediction_coarse_accuracy: 0.3962 - prediction_medium_accuracy: 0.6628 - prediction_fine_accuracy: 0.5850 - val_loss: -42.0958 - val_prediction_coarse_accuracy: 0.3997 - val_prediction_medium_accuracy: 0.6969 - val_prediction_fine_accuracy: 0.6207 - lr: 1.4240e-04\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.1835 - prediction_coarse_accuracy: 0.4026 - prediction_medium_accuracy: 0.6748 - prediction_fine_accuracy: 0.5987\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.26% | Val_Accuracy = 39.93% | LossWeight = 0.52 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 67.48% | Val_Accuracy = 70.26% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 59.87% | Val_Accuracy = 62.62% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 49: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 48ms/step - loss: -76.1835 - prediction_coarse_accuracy: 0.4026 - prediction_medium_accuracy: 0.6748 - prediction_fine_accuracy: 0.5987 - val_loss: -42.1376 - val_prediction_coarse_accuracy: 0.3993 - val_prediction_medium_accuracy: 0.7026 - val_prediction_fine_accuracy: 0.6262 - lr: 1.3528e-04\n",
      "Epoch 50/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.7760 - prediction_coarse_accuracy: 0.3976 - prediction_medium_accuracy: 0.6808 - prediction_fine_accuracy: 0.6050\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.76% | Val_Accuracy = 40.00% | LossWeight = 0.52 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 68.07% | Val_Accuracy = 69.05% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 60.49% | Val_Accuracy = 61.44% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 50: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 48ms/step - loss: -76.7622 - prediction_coarse_accuracy: 0.3976 - prediction_medium_accuracy: 0.6807 - prediction_fine_accuracy: 0.6049 - val_loss: -41.9477 - val_prediction_coarse_accuracy: 0.4000 - val_prediction_medium_accuracy: 0.6905 - val_prediction_fine_accuracy: 0.6144 - lr: 1.2851e-04\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.8469 - prediction_coarse_accuracy: 0.3995 - prediction_medium_accuracy: 0.6813 - prediction_fine_accuracy: 0.6041\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.95% | Val_Accuracy = 39.99% | LossWeight = 0.52 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 68.13% | Val_Accuracy = 70.59% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 60.41% | Val_Accuracy = 63.11% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 51: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 47ms/step - loss: -76.8469 - prediction_coarse_accuracy: 0.3995 - prediction_medium_accuracy: 0.6813 - prediction_fine_accuracy: 0.6041 - val_loss: -42.0287 - val_prediction_coarse_accuracy: 0.3999 - val_prediction_medium_accuracy: 0.7059 - val_prediction_fine_accuracy: 0.6311 - lr: 1.2209e-04\n",
      "Epoch 52/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.7337 - prediction_coarse_accuracy: 0.4008 - prediction_medium_accuracy: 0.6790 - prediction_fine_accuracy: 0.6092\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.09% | Val_Accuracy = 39.98% | LossWeight = 0.52 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 67.89% | Val_Accuracy = 69.90% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 60.93% | Val_Accuracy = 62.91% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 52: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 48ms/step - loss: -76.7179 - prediction_coarse_accuracy: 0.4009 - prediction_medium_accuracy: 0.6789 - prediction_fine_accuracy: 0.6093 - val_loss: -42.0587 - val_prediction_coarse_accuracy: 0.3998 - val_prediction_medium_accuracy: 0.6990 - val_prediction_fine_accuracy: 0.6291 - lr: 1.1598e-04\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -77.0188 - prediction_coarse_accuracy: 0.3993 - prediction_medium_accuracy: 0.6829 - prediction_fine_accuracy: 0.6144\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.93% | Val_Accuracy = 39.96% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 68.29% | Val_Accuracy = 70.00% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 61.44% | Val_Accuracy = 63.40% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 53: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -77.0188 - prediction_coarse_accuracy: 0.3993 - prediction_medium_accuracy: 0.6829 - prediction_fine_accuracy: 0.6144 - val_loss: -42.0082 - val_prediction_coarse_accuracy: 0.3996 - val_prediction_medium_accuracy: 0.7000 - val_prediction_fine_accuracy: 0.6340 - lr: 1.1018e-04\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -76.9911 - prediction_coarse_accuracy: 0.4008 - prediction_medium_accuracy: 0.6890 - prediction_fine_accuracy: 0.6203\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.08% | Val_Accuracy = 39.97% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 68.90% | Val_Accuracy = 66.89% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.03% | Val_Accuracy = 61.09% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 54: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 48ms/step - loss: -76.9911 - prediction_coarse_accuracy: 0.4008 - prediction_medium_accuracy: 0.6890 - prediction_fine_accuracy: 0.6203 - val_loss: -41.5844 - val_prediction_coarse_accuracy: 0.3997 - val_prediction_medium_accuracy: 0.6689 - val_prediction_fine_accuracy: 0.6109 - lr: 1.0467e-04\n",
      "Epoch 55/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.8830 - prediction_coarse_accuracy: 0.3993 - prediction_medium_accuracy: 0.6804 - prediction_fine_accuracy: 0.6125\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.92% | Val_Accuracy = 39.96% | LossWeight = 0.52 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 68.05% | Val_Accuracy = 70.16% | LossWeight = 0.20 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 61.25% | Val_Accuracy = 63.43% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 55: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 35s 45ms/step - loss: -76.8993 - prediction_coarse_accuracy: 0.3992 - prediction_medium_accuracy: 0.6805 - prediction_fine_accuracy: 0.6125 - val_loss: -42.0486 - val_prediction_coarse_accuracy: 0.3996 - val_prediction_medium_accuracy: 0.7016 - val_prediction_fine_accuracy: 0.6343 - lr: 9.9440e-05\n",
      "Epoch 56/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -76.9469 - prediction_coarse_accuracy: 0.3991 - prediction_medium_accuracy: 0.6944 - prediction_fine_accuracy: 0.6249\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.91% | Val_Accuracy = 39.88% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.44% | Val_Accuracy = 70.79% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.49% | Val_Accuracy = 63.87% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 56: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -76.9448 - prediction_coarse_accuracy: 0.3991 - prediction_medium_accuracy: 0.6944 - prediction_fine_accuracy: 0.6249 - val_loss: -42.0724 - val_prediction_coarse_accuracy: 0.3988 - val_prediction_medium_accuracy: 0.7079 - val_prediction_fine_accuracy: 0.6387 - lr: 9.4468e-05\n",
      "Epoch 57/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -77.1055 - prediction_coarse_accuracy: 0.3976 - prediction_medium_accuracy: 0.6866 - prediction_fine_accuracy: 0.6227\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.77% | Val_Accuracy = 39.66% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 68.67% | Val_Accuracy = 70.67% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.28% | Val_Accuracy = 64.57% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 57: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -77.0908 - prediction_coarse_accuracy: 0.3977 - prediction_medium_accuracy: 0.6867 - prediction_fine_accuracy: 0.6228 - val_loss: -42.0427 - val_prediction_coarse_accuracy: 0.3966 - val_prediction_medium_accuracy: 0.7067 - val_prediction_fine_accuracy: 0.6457 - lr: 8.9745e-05\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -77.2477 - prediction_coarse_accuracy: 0.3985 - prediction_medium_accuracy: 0.6954 - prediction_fine_accuracy: 0.6285\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.85% | Val_Accuracy = 39.78% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.54% | Val_Accuracy = 70.92% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.85% | Val_Accuracy = 64.71% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 58: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -77.2477 - prediction_coarse_accuracy: 0.3985 - prediction_medium_accuracy: 0.6954 - prediction_fine_accuracy: 0.6285 - val_loss: -42.0860 - val_prediction_coarse_accuracy: 0.3978 - val_prediction_medium_accuracy: 0.7092 - val_prediction_fine_accuracy: 0.6471 - lr: 8.5258e-05\n",
      "Epoch 59/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -77.3373 - prediction_coarse_accuracy: 0.3973 - prediction_medium_accuracy: 0.6933 - prediction_fine_accuracy: 0.6289\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.74% | Val_Accuracy = 39.83% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.32% | Val_Accuracy = 70.98% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.88% | Val_Accuracy = 64.07% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 59: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 47ms/step - loss: -77.3288 - prediction_coarse_accuracy: 0.3974 - prediction_medium_accuracy: 0.6932 - prediction_fine_accuracy: 0.6288 - val_loss: -41.8504 - val_prediction_coarse_accuracy: 0.3983 - val_prediction_medium_accuracy: 0.7098 - val_prediction_fine_accuracy: 0.6407 - lr: 8.0995e-05\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -77.2073 - prediction_coarse_accuracy: 0.3996 - prediction_medium_accuracy: 0.6908 - prediction_fine_accuracy: 0.6249\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.96% | Val_Accuracy = 39.99% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.08% | Val_Accuracy = 71.13% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.49% | Val_Accuracy = 64.85% | LossWeight = 0.18 \u001b[0m\n",
      "\n",
      "Epoch 60: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 45ms/step - loss: -77.2073 - prediction_coarse_accuracy: 0.3996 - prediction_medium_accuracy: 0.6908 - prediction_fine_accuracy: 0.6249 - val_loss: -42.1311 - val_prediction_coarse_accuracy: 0.3999 - val_prediction_medium_accuracy: 0.7113 - val_prediction_fine_accuracy: 0.6485 - lr: 7.6945e-05\n",
      "Epoch 61/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -77.3700 - prediction_coarse_accuracy: 0.3977 - prediction_medium_accuracy: 0.6936 - prediction_fine_accuracy: 0.6282\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.77% | Val_Accuracy = 39.97% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.36% | Val_Accuracy = 71.34% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 62.82% | Val_Accuracy = 65.05% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 61: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -77.3700 - prediction_coarse_accuracy: 0.3977 - prediction_medium_accuracy: 0.6936 - prediction_fine_accuracy: 0.6282 - val_loss: -42.1383 - val_prediction_coarse_accuracy: 0.3997 - val_prediction_medium_accuracy: 0.7134 - val_prediction_fine_accuracy: 0.6505 - lr: 7.3098e-05\n",
      "Epoch 62/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -77.3610 - prediction_coarse_accuracy: 0.3996 - prediction_medium_accuracy: 0.6977 - prediction_fine_accuracy: 0.6344\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.95% | Val_Accuracy = 39.94% | LossWeight = 0.54 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.76% | Val_Accuracy = 72.12% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 63.43% | Val_Accuracy = 65.69% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 62: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 46ms/step - loss: -77.3780 - prediction_coarse_accuracy: 0.3995 - prediction_medium_accuracy: 0.6976 - prediction_fine_accuracy: 0.6343 - val_loss: -42.1556 - val_prediction_coarse_accuracy: 0.3994 - val_prediction_medium_accuracy: 0.7212 - val_prediction_fine_accuracy: 0.6569 - lr: 6.9443e-05\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -77.1424 - prediction_coarse_accuracy: 0.3993 - prediction_medium_accuracy: 0.6995 - prediction_fine_accuracy: 0.6364\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.93% | Val_Accuracy = 39.98% | LossWeight = 0.54 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.95% | Val_Accuracy = 70.75% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 63.64% | Val_Accuracy = 64.57% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 63: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 36s 47ms/step - loss: -77.1424 - prediction_coarse_accuracy: 0.3993 - prediction_medium_accuracy: 0.6995 - prediction_fine_accuracy: 0.6364 - val_loss: -42.1664 - val_prediction_coarse_accuracy: 0.3998 - val_prediction_medium_accuracy: 0.7075 - val_prediction_fine_accuracy: 0.6457 - lr: 6.5971e-05\n",
      "Epoch 64/100\n",
      "780/781 [============================>.] - ETA: 0s - loss: -77.0586 - prediction_coarse_accuracy: 0.4020 - prediction_medium_accuracy: 0.6946 - prediction_fine_accuracy: 0.6354\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 40.21% | Val_Accuracy = 39.94% | LossWeight = 0.53 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.46% | Val_Accuracy = 71.93% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 63.53% | Val_Accuracy = 65.79% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 64: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 48ms/step - loss: -77.0513 - prediction_coarse_accuracy: 0.4021 - prediction_medium_accuracy: 0.6946 - prediction_fine_accuracy: 0.6353 - val_loss: -42.2379 - val_prediction_coarse_accuracy: 0.3994 - val_prediction_medium_accuracy: 0.7193 - val_prediction_fine_accuracy: 0.6579 - lr: 6.2672e-05\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -77.5977 - prediction_coarse_accuracy: 0.3977 - prediction_medium_accuracy: 0.7016 - prediction_fine_accuracy: 0.6439\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.77% | Val_Accuracy = 39.86% | LossWeight = 0.54 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 70.16% | Val_Accuracy = 72.01% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 64.39% | Val_Accuracy = 65.90% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 65: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 37s 48ms/step - loss: -77.5977 - prediction_coarse_accuracy: 0.3977 - prediction_medium_accuracy: 0.7016 - prediction_fine_accuracy: 0.6439 - val_loss: -42.2211 - val_prediction_coarse_accuracy: 0.3986 - val_prediction_medium_accuracy: 0.7201 - val_prediction_fine_accuracy: 0.6590 - lr: 5.9539e-05\n",
      "Epoch 66/100\n",
      "781/781 [==============================] - ETA: 0s - loss: -77.8507 - prediction_coarse_accuracy: 0.3962 - prediction_medium_accuracy: 0.6987 - prediction_fine_accuracy: 0.6361\n",
      "\u001b[91m \u001b[1m • Coarse Accuracy = 39.62% | Val_Accuracy = 39.82% | LossWeight = 0.54 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Medium Accuracy = 69.87% | Val_Accuracy = 71.99% | LossWeight = 0.19 \u001b[0m\n",
      "\u001b[91m \u001b[1m • Fine   Accuracy = 63.61% | Val_Accuracy = 65.52% | LossWeight = 0.17 \u001b[0m\n",
      "\n",
      "Epoch 66: val_prediction_fine_accuracy did not improve from 0.73160\n",
      "781/781 [==============================] - 35s 45ms/step - loss: -77.8507 - prediction_coarse_accuracy: 0.3962 - prediction_medium_accuracy: 0.6987 - prediction_fine_accuracy: 0.6361 - val_loss: -42.1356 - val_prediction_coarse_accuracy: 0.3982 - val_prediction_medium_accuracy: 0.7199 - val_prediction_fine_accuracy: 0.6552 - lr: 5.6562e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26696/2477457612.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds)\u001b[0m\n\u001b[0;32m    506\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 507\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '../../logs/3_CIFAR_10/HD_CapsNet/Mod_4_1_2/trained_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26696/2477457612.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     history = model.fit(training_generator,\n\u001b[0m\u001b[0;32m      6\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1371\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2032\u001b[0m     \"\"\"\n\u001b[0;32m   2033\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2034\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m   def train_on_batch(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m       \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   4017\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4018\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4019\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4020\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4021\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[0mvalidate_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"validate_shape\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0m\u001b[0;32m    951\u001b[0m           self.handle, value_tensor, name=name, **kwargs)\n\u001b[0;32m    952\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[0;32m    139\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AssignVariableOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"validate_shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         validate_shape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_save_dir = str(directory+'/trained_model.h5')\n",
    "try:\n",
    "    model.load_weights(model_save_dir)\n",
    "except:\n",
    "    history = model.fit(training_generator,\n",
    "                        steps_per_epoch = int(dataset['x_train'].shape[0] / train_params[\"batch_size\"]),\n",
    "                        epochs = train_params[\"n_epochs\"],\n",
    "                        validation_data = ([dataset['x_test'],\n",
    "                                            dataset['y_test_coarse'],dataset['y_test_medium'],dataset['y_test_fine']],\n",
    "                                           [dataset['y_test_coarse'],dataset['y_test_medium'],dataset['y_test_fine']]),\n",
    "                        callbacks = [tb,log,change_lw,lr_decay,checkpoint],\n",
    "                        verbose=1)\n",
    "    model.save_weights(model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    history_dict = history.history\n",
    "\n",
    "    plotter = tfdocs.plots.HistoryPlotter()\n",
    "    plotter.plot({\"Coarse\": history}, metric = \"prediction_coarse_accuracy\")\n",
    "    plotter.plot({\"Medium\": history}, metric = \"prediction_medium_accuracy\")\n",
    "    plotter.plot({\"Fine\": history}, metric = \"prediction_fine_accuracy\")\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "except:\n",
    "    print('Trained model weights loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5175ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plotter = tfdocs.plots.HistoryPlotter()\n",
    "    plotter.plot({\"loss\": history}, metric = \"loss\")\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "except:\n",
    "    print('Trained model weights loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08f53b",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3170fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = keras.Model(model.inputs[:1], model.output)\n",
    "\n",
    "lossfn = models.MarginLoss()\n",
    "final_model.compile(optimizer='adam', \n",
    "                    loss={'prediction_fine' : lossfn,\n",
    "                          'prediction_medium' : lossfn,\n",
    "                          'prediction_coarse' : lossfn},\n",
    "\n",
    "                    loss_weights={'prediction_fine' : lossweight['fine_lw'],\n",
    "                                  'prediction_medium' : lossweight['medium_lw'],\n",
    "                                  'prediction_coarse' : lossweight['coarse_lw']},\n",
    "\n",
    "                    metrics={'prediction_fine': 'accuracy',\n",
    "                             'prediction_medium': 'accuracy',\n",
    "                             'prediction_coarse': 'accuracy'\n",
    "                            }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis = models.model_analysis(final_model, dataset)\n",
    "results = model_analysis.evaluate()\n",
    "predictions = model_analysis.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = [dataset['y_test_coarse'],dataset['y_test_medium'],dataset['y_test_fine']]\n",
    "pred_label = [predictions[0],predictions[1],predictions[2]]\n",
    "metrics.lvl_wise_metric(true_label,pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_measurements,consistency,exact_match = metrics.hmeasurements(true_label,\n",
    "                                       pred_label,\n",
    "                                       dataset['tree'])\n",
    "print('\\nHierarchical Precision =',h_measurements[0],\n",
    "      '\\nHierarchical Recall =', h_measurements[1],\n",
    "      '\\nHierarchical F1-Score =',h_measurements[2],\n",
    "      '\\nConsistency = ', consistency,\n",
    "      '\\nExact Match = ', exact_match,\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4ed43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d06b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
